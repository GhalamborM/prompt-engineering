# راهنمای جامع مهندسی پرامپت (Prompt Engineering)

## فهرست مطالب
1. [مقدمه](#مقدمه)
2. [مفهوم مهندسی پرامپت](#مفهوم-مهندسی-پرامپت)
3. [تنظیمات خروجی مدل‌های زبانی بزرگ](#تنظیمات-خروجی-مدلهای-زبانی-بزرگ)
   - [طول خروجی](#طول-خروجی)
   - [کنترل‌های نمونه‌برداری](#کنترلهای-نمونهبرداری)
   - [دما (Temperature)](#دما-temperature)
   - [Top-K و Top-P](#top-k-و-top-p)
   - [ترکیب تنظیمات](#ترکیب-تنظیمات)
4. [تکنیک‌های مهندسی پرامپت](#تکنیکهای-مهندسی-پرامپت)
   - [پرامپت صفر-شات (Zero-shot)](#پرامپت-صفر-شات-zero-shot)
   - [پرامپت تک-شات و چند-شات (One-shot & Few-shot)](#پرامپت-تک-شات-و-چند-شات-one-shot--few-shot)
   - [پرامپت سیستمی (System Prompting)](#پرامپت-سیستمی-system-prompting)
   - [پرامپت نقش (Role Prompting)](#پرامپت-نقش-role-prompting)
   - [پرامپت زمینه‌ای (Contextual Prompting)](#پرامپت-زمینهای-contextual-prompting)
   - [پرامپت قدم به عقب (Step-back Prompting)](#پرامپت-قدم-به-عقب-step-back-prompting)
   - [زنجیره تفکر (Chain of Thought)](#زنجیره-تفکر-chain-of-thought)
   - [خودسازگاری (Self-consistency)](#خودسازگاری-self-consistency)
   - [درخت تفکرات (Tree of Thoughts)](#درخت-تفکرات-tree-of-thoughts)
   - [واکنش (ReAct)](#واکنش-react)
5. [پرامپت برای کدنویسی](#پرامپت-برای-کدنویسی)
   - [نوشتن کد](#نوشتن-کد)
   - [توضیح کد](#توضیح-کد)
   - [ترجمه کد](#ترجمه-کد)
   - [اشکال‌زدایی و بررسی کد](#اشکالزدایی-و-بررسی-کد)
6. [بهترین شیوه‌های مهندسی پرامپت](#بهترین-شیوههای-مهندسی-پرامپت)
   - [ارائه مثال‌ها](#ارائه-مثالها)
   - [طراحی با سادگی](#طراحی-با-سادگی)
   - [مشخص کردن خروجی](#مشخص-کردن-خروجی)
   - [استفاده از دستورالعمل‌ها به جای محدودیت‌ها](#استفاده-از-دستورالعملها-به-جای-محدودیتها)
   - [کنترل طول توکن](#کنترل-طول-توکن)
   - [استفاده از متغیرها در پرامپت‌ها](#استفاده-از-متغیرها-در-پرامپتها)
   - [آزمایش با فرمت‌های ورودی و سبک‌های نوشتاری](#آزمایش-با-فرمتهای-ورودی-و-سبکهای-نوشتاری)
   - [مستندسازی تلاش‌های مختلف پرامپت](#مستندسازی-تلاشهای-مختلف-پرامپت)
7. [نمونه کاربردهای عملی](#نمونه-کاربردهای-عملی)
8. [جمع‌بندی](#جمعبندی)

## مقدمه

مهندسی پرامپت (Prompt Engineering) هنر و علم طراحی دستورالعمل‌های مؤثر برای مدل‌های زبانی بزرگ (LLM) است. در دنیای هوش مصنوعی امروز، توانایی نوشتن پرامپت‌های مؤثر به یک مهارت ضروری تبدیل شده است. برای استفاده از مدل‌های زبانی بزرگ مانند Gemini، GPT، Claude یا مدل‌های متن‌باز مانند Gemma یا LLaMA، نیازی نیست که دانشمند داده یا مهندس یادگیری ماشین باشید - هر کسی می‌تواند یک پرامپت بنویسد.

با این حال، طراحی پرامپت‌های مؤثر می‌تواند پیچیده باشد. جنبه‌های مختلفی از پرامپت شما بر کارآیی آن تأثیر می‌گذارد: مدلی که استفاده می‌کنید، داده‌های آموزشی مدل، تنظیمات مدل، انتخاب کلمات، سبک و لحن، ساختار و زمینه همگی مهم هستند. بنابراین، مهندسی پرامپت یک فرآیند تکراری است. پرامپت‌های نامناسب می‌توانند منجر به پاسخ‌های مبهم، نادرست شوند و توانایی مدل برای ارائه خروجی معنادار را مختل کنند.

در این راهنمای جامع، ما به بررسی دقیق مهندسی پرامپت می‌پردازیم. تکنیک‌های مختلف پرامپت را برای کمک به شروع کار شما معرفی می‌کنیم و نکات و بهترین شیوه‌ها را برای تبدیل شدن به یک متخصص پرامپت به اشتراک می‌گذاریم. همچنین برخی از چالش‌هایی که ممکن است هنگام طراحی پرامپت‌ها با آن‌ها مواجه شوید را مورد بحث قرار می‌دهیم.

## مفهوم مهندسی پرامپت

به یاد داشته باشید که یک مدل زبانی بزرگ (LLM) چگونه کار می‌کند؛ این یک موتور پیش‌بینی است. مدل متن متوالی را به عنوان ورودی می‌گیرد و سپس پیش‌بینی می‌کند که توکن بعدی چه باید باشد، بر اساس داده‌هایی که با آن‌ها آموزش دیده است. LLM برای انجام این کار بارها و بارها عملیاتی می‌شود، توکن پیش‌بینی شده قبلی را به انتهای متن متوالی برای پیش‌بینی توکن بعدی اضافه می‌کند. پیش‌بینی توکن بعدی بر اساس رابطه بین آنچه در توکن‌های قبلی است و آنچه LLM در طول آموزش خود دیده است، انجام می‌شود.

وقتی یک پرامپت می‌نویسید، در حال تلاش برای تنظیم LLM برای پیش‌بینی توالی درست توکن‌ها هستید. مهندسی پرامپت فرآیند طراحی پرامپت‌های با کیفیت بالا است که LLM‌ها را برای تولید خروجی‌های دقیق هدایت می‌کند. این فرآیند شامل آزمایش برای یافتن بهترین پرامپت، بهینه‌سازی طول پرامپت و ارزیابی سبک نوشتاری و ساختار یک پرامپت در رابطه با وظیفه است.

این پرامپت‌ها می‌توانند برای دستیابی به انواع مختلفی از وظایف درک و تولید مانند خلاصه‌سازی متن، استخراج اطلاعات، پرسش و پاسخ، طبقه‌بندی متن، ترجمه زبان یا کد، تولید کد و مستندسازی کد یا استدلال استفاده شوند.

## تنظیمات خروجی مدل‌های زبانی بزرگ

پس از انتخاب مدل، باید تنظیمات مدل را مشخص کنید. اکثر مدل‌های زبانی بزرگ دارای گزینه‌های تنظیم مختلفی هستند که خروجی LLM را کنترل می‌کنند. مهندسی پرامپت مؤثر نیاز به تنظیم بهینه این پیکربندی‌ها برای وظیفه شما دارد.

### طول خروجی

یک تنظیم مهم، تعداد توکن‌هایی است که در یک پاسخ تولید می‌شوند. تولید توکن‌های بیشتر نیاز به محاسبات بیشتری از LLM دارد، که منجر به مصرف انرژی بالاتر، زمان پاسخ بالقوه کندتر و هزینه‌های بالاتر می‌شود.

کاهش طول خروجی LLM باعث نمی‌شود که LLM در خروجی که ایجاد می‌کند از نظر سبک یا متنی مختصرتر شود، فقط باعث می‌شود LLM پس از رسیدن به محدودیت، پیش‌بینی توکن‌های بیشتر را متوقف کند. اگر نیازهای شما به طول خروجی کوتاه نیاز دارد، احتمالاً باید پرامپت خود را نیز برای تطبیق با آن مهندسی کنید.

محدودیت طول خروجی به ویژه برای برخی از تکنیک‌های پرامپت LLM، مانند ReAct، مهم است، جایی که LLM پس از پاسخی که می‌خواهید، به انتشار توکن‌های بی‌فایده ادامه می‌دهد.

توجه داشته باشید، تولید توکن‌های بیشتر نیاز به محاسبات بیشتری از LLM دارد، که منجر به مصرف انرژی بالاتر و زمان پاسخ بالقوه کندتر می‌شود، که منجر به هزینه‌های بالاتر می‌شود.

### کنترل‌های نمونه‌برداری

LLM‌ها به طور رسمی یک توکن واحد را پیش‌بینی نمی‌کنند. در عوض، LLM‌ها احتمالات را برای اینکه توکن بعدی چه می‌تواند باشد پیش‌بینی می‌کنند، که هر توکن در واژگان LLM یک احتمال دریافت می‌کند. سپس از آن احتمالات توکن نمونه‌برداری می‌شود تا تعیین شود که توکن بعدی تولید شده چه خواهد بود.

دما (Temperature)، Top-K و Top-P رایج‌ترین تنظیمات پیکربندی هستند که تعیین می‌کنند چگونه احتمالات توکن پیش‌بینی شده برای انتخاب یک توکن خروجی واحد پردازش می‌شوند.

### دما (Temperature)

دما درجه تصادفی بودن در انتخاب توکن را کنترل می‌کند. دماهای پایین‌تر برای پرامپت‌هایی که انتظار پاسخ قطعی‌تری دارند مناسب هستند، در حالی که دماهای بالاتر می‌توانند منجر به نتایج متنوع‌تر یا غیرمنتظره شوند. دمای 0 (رمزگشایی حریصانه) قطعی است: توکن با بالاترین احتمال همیشه انتخاب می‌شود.

دماهای نزدیک به حداکثر تمایل به ایجاد خروجی تصادفی‌تر دارند. و همانطور که دما بالاتر و بالاتر می‌رود، همه توکن‌ها به یک اندازه احتمال دارند که توکن پیش‌بینی شده بعدی باشند.

راهنمای تنظیم دما:
- **دمای پایین (0-0.3)**: برای وظایف واقعیت‌محور مانند پاسخ به سؤالات واقعی، طبقه‌بندی، یا استخراج اطلاعات
- **دمای متوسط (0.3-0.7)**: برای پاسخ‌های متعادل که نیاز به ترکیبی از دقت و خلاقیت دارند
- **دمای بالا (0.7-1)**: برای تولید محتوای خلاقانه مانند داستان‌ها، شعر، یا ایده‌های خلاقانه

### Top-K و Top-P

Top-K و Top-P (همچنین به عنوان نمونه‌برداری هسته‌ای شناخته می‌شود) دو تنظیم نمونه‌برداری هستند که در LLM‌ها برای محدود کردن توکن بعدی پیش‌بینی شده به توکن‌هایی با احتمالات پیش‌بینی شده بالا استفاده می‌شوند. مانند دما، این تنظیمات نمونه‌برداری تصادفی بودن و تنوع متن تولید شده را کنترل می‌کنند.

- **نمونه‌برداری Top-K**: K توکن محتمل‌ترین را از توزیع پیش‌بینی شده مدل انتخاب می‌کند. هرچه Top-K بالاتر باشد، خروجی مدل خلاقانه‌تر و متنوع‌تر است؛ هرچه Top-K پایین‌تر باشد، خروجی مدل محدودتر و واقعی‌تر است. Top-K برابر با 1 معادل رمزگشایی حریصانه است.

- **نمونه‌برداری Top-P**: توکن‌های برتری را انتخاب می‌کند که احتمال تجمعی آن‌ها از یک مقدار خاص (P) تجاوز نکند. مقادیر برای P از 0 (رمزگشایی حریصانه) تا 1 (همه توکن‌ها در واژگان LLM) متغیر است.

بهترین راه برای انتخاب بین Top-K و Top-P این است که با هر دو روش (یا هر دو با هم) آزمایش کنید و ببینید کدام یک نتایجی را که به دنبال آن هستید تولید می‌کند.

### ترکیب تنظیمات

انتخاب بین Top-K، Top-P، دما و تعداد توکن‌هایی که باید تولید شوند، به کاربرد خاص و نتیجه مورد نظر بستگی دارد، و تنظیمات همه بر یکدیگر تأثیر می‌گذارند. همچنین مهم است که مطمئن شوید درک می‌کنید که مدل انتخابی شما چگونه تنظیمات نمونه‌برداری مختلف را با هم ترکیب می‌کند.

اگر دما، Top-K و Top-P همه در دسترس باشند، توکن‌هایی که هم معیارهای Top-K و هم Top-P را برآورده می‌کنند، نامزدهای توکن پیش‌بینی شده بعدی هستند، و سپس دما برای نمونه‌برداری از توکن‌هایی که از معیارهای Top-K و Top-P عبور کرده‌اند اعمال می‌شود.

به عنوان یک نقطه شروع کلی:
- دمای 0.2، Top-P برابر با 0.95 و Top-K برابر با 30 به شما نتایج نسبتاً منسجمی می‌دهد که می‌تواند خلاقانه باشد اما نه بیش از حد.
- اگر می‌خواهید نتایج به ویژه خلاقانه‌ای داشته باشید، سعی کنید با دمای 0.9، Top-P برابر با 0.99 و Top-K برابر با 40 شروع کنید.
- و اگر می‌خواهید نتایج کمتر خلاقانه‌ای داشته باشید، سعی کنید با دمای 0.1، Top-P برابر با 0.9 و Top-K برابر با 20 شروع کنید.
- در نهایت، اگر وظیفه شما همیشه یک پاسخ صحیح واحد دارد (مثلاً پاسخ به یک مسئله ریاضی)، با دمای 0 شروع کنید.

**نکته**: با آزادی بیشتر (دمای بالاتر، Top-K، Top-P و توکن‌های خروجی)، LLM ممکن است متنی تولید کند که کمتر مرتبط است.

**هشدار**: آیا تا به حال پاسخی را دیده‌اید که با مقدار زیادی کلمات پرکننده به پایان برسد؟ این همچنین به عنوان "باگ حلقه تکرار" شناخته می‌شود، که یک مشکل رایج در مدل‌های زبانی بزرگ است که در آن مدل در یک چرخه گیر می‌کند و مکرراً همان کلمه (پرکننده)، عبارت یا ساختار جمله را تولید می‌کند، که اغلب با تنظیمات نامناسب دما و top-k/top-p تشدید می‌شود. این می‌تواند هم در تنظیمات دمای پایین و هم بالا رخ دهد، اگرچه به دلایل مختلف. در دماهای پایین، مدل بیش از حد قطعی می‌شود و به شدت به مسیر با بالاترین احتمال می‌چسبد، که می‌تواند منجر به یک حلقه شود اگر آن مسیر به متن تولید شده قبلی بازگردد. برعکس، در دماهای بالا، خروجی مدل بیش از حد تصادفی می‌شود، که احتمال اینکه یک کلمه یا عبارت انتخاب شده به طور تصادفی، به شانس، به یک حالت قبلی بازگردد را افزایش می‌دهد، که به دلیل تعداد زیاد گزینه‌های موجود یک حلقه ایجاد می‌کند. در هر دو مورد، فرآیند نمونه‌برداری مدل "گیر می‌کند"، که منجر به خروجی یکنواخت و بی‌فایده می‌شود تا زمانی که پنجره خروجی پر شود. حل این مشکل اغلب نیاز به تنظیم دقیق مقادیر دما و top-k/top-p برای یافتن تعادل بهینه بین قطعیت و تصادفی بودن دارد.

## تکنیک‌های مهندسی پرامپت

LLM‌ها برای پیروی از دستورالعمل‌ها تنظیم شده‌اند و روی مقادیر زیادی از داده‌ها آموزش دیده‌اند تا بتوانند یک پرامپت را درک کنند و پاسخی تولید کنند. اما LLM‌ها کامل نیستند؛ هرچه متن پرامپت شما واضح‌تر باشد، برای LLM بهتر است تا متن بعدی محتمل را پیش‌بینی کند. علاوه بر این، تکنیک‌های خاصی که از نحوه آموزش LLM‌ها و نحوه کار LLM‌ها استفاده می‌کنند، به شما کمک می‌کنند تا نتایج مرتبط را از LLM‌ها دریافت کنید.

حالا که می‌دانیم مهندسی پرامپت چیست و چه چیزی نیاز دارد، بیایید به برخی از مثال‌های مهم‌ترین تکنیک‌های پرامپت بپردازیم.

### پرامپت صفر-شات (Zero-shot)

یک پرامپت صفر-شات ساده‌ترین نوع پرامپت است. این فقط توصیفی از یک وظیفه و برخی متن‌ها را برای شروع کار LLM ارائه می‌دهد. این ورودی می‌تواند هر چیزی باشد: یک سؤال، شروع یک داستان، یا دستورالعمل‌ها. نام صفر-شات به معنای 'بدون مثال' است.

**مثال پرامپت صفر-شات برای طبقه‌بندی نظرات فیلم:**

```
نظرات فیلم را به عنوان مثبت، خنثی یا منفی طبقه‌بندی کن.
نظر: "او" مطالعه‌ای تکان‌دهنده است که مسیر بشریت را در صورت تکامل کنترل‌نشده هوش مصنوعی نشان می‌دهد. کاش فیلم‌های بیشتری مانند این شاهکار وجود داشت.
احساس:
```

دمای مدل باید روی عدد پایینی تنظیم شود، زیرا نیازی به خلاقیت نیست. توجه کنید که کلمات "تکان‌دهنده" و "شاهکار" باید پیش‌بینی را کمی پیچیده‌تر کنند، زیرا هر دو کلمه در یک جمله استفاده می‌شوند.

وقتی صفر-شات کار نمی‌کند، می‌توانید نمونه‌ها یا مثال‌هایی را در پرامپت ارائه دهید، که منجر به پرامپت "تک-شات" و "چند-شات" می‌شود.

### پرامپت تک-شات و چند-شات (One-shot & Few-shot)

هنگام ایجاد پرامپت برای مدل‌های هوش مصنوعی، ارائه مثال‌ها مفید است. این مثال‌ها می‌توانند به مدل کمک کنند تا آنچه را که از آن می‌خواهید درک کند. مثال‌ها به ویژه زمانی مفید هستند که می‌خواهید مدل را به سمت یک ساختار یا الگوی خروجی خاص هدایت کنید.

یک پرامپت تک-شات، یک مثال واحد ارائه می‌دهد، از این رو نام تک-شات. ایده این است که مدل مثالی دارد که می‌تواند از آن تقلید کند تا بهترین کار را برای تکمیل وظیفه انجام دهد.

یک پرامپت چند-شات چندین مثال را به مدل ارائه می‌دهد. این رویکرد الگویی را به مدل نشان می‌دهد که باید از آن پیروی کند. ایده مشابه تک-شات است، اما چندین مثال از الگوی مورد نظر شانس پیروی مدل از الگو را افزایش می‌دهد.

**مثال پرامپت چند-شات برای طبقه‌بندی احساسات:**

```
طبقه‌بندی احساسات:
متن: "این رستوران افتضاح بود."
احساس: منفی

متن: "غذا خوب بود، اما خدمات می‌توانست بهتر باشد."
احساس: خنثی

متن: "من عاشق این محصول هستم! بهترین خرید سال من بود."
احساس: مثبت

متن: "قیمت‌ها کمی بالاست، اما کیفیت عالی است."
احساس:
```

تعداد مثال‌هایی که برای پرامپت چند-شات نیاز دارید به چند عامل بستگی دارد، از جمله پیچیدگی وظیفه، کیفیت مثال‌ها و قابلیت‌های مدل هوش مصنوعی تولیدی (gen AI) که استفاده می‌کنید. به عنوان یک قاعده کلی، باید حداقل از سه تا پنج مثال برای پرامپت چند-شات استفاده کنید. با این حال، ممکن است برای وظایف پیچیده‌تر نیاز به استفاده از مثال‌های بیشتری داشته باشید، یا ممکن است به دلیل محدودیت طول ورودی مدل خود نیاز به استفاده از مثال‌های کمتری داشته باشید.

### پرامپت سیستمی (System Prompting)

پرامپت سیستمی یک روش قدرتمند برای تنظیم رفتار کلی مدل است. این نوع پرامپت به مدل می‌گوید که چگونه باید رفتار کند، چه نوع پاسخ‌هایی باید تولید کند، و چه محدودیت‌هایی باید رعایت کند.

**مثال پرامپت سیستمی:**

```
تو یک دستیار مفید، دقیق و صادق هستی. همیشه به کاربر کمک می‌کنی و اطلاعات دقیق ارائه می‌دهی. اگر پاسخ سؤالی را نمی‌دانی، به جای حدس زدن، صادقانه می‌گویی که نمی‌دانی.
```

پرامپت‌های سیستمی معمولاً در ابتدای مکالمه قرار می‌گیرند و می‌توانند به عنوان دستورالعمل‌های کلی برای مدل عمل کنند. آنها به ویژه برای تنظیم لحن، سبک و محدودیت‌های پاسخ مفید هستند.

### پرامپت نقش (Role Prompting)

پرامپت نقش یک تکنیک قدرتمند است که در آن به مدل یک نقش یا شخصیت خاص داده می‌شود تا از آن دیدگاه پاسخ دهد. این می‌تواند به تولید پاسخ‌های تخصصی‌تر، متمرکزتر یا خلاقانه‌تر کمک کند.

**مثال پرامپت نقش:**

```
تو یک متخصص برنامه‌نویسی پایتون با ۱۵ سال تجربه هستی. لطفاً کد زیر را بررسی کن و مشکلات آن را توضیح بده:

def calculate_average(numbers):
    total = 0
    for num in numbers:
        total += num
    return total / len(numbers)
```

با تعیین یک نقش خاص، مدل را تشویق می‌کنید تا دانش و دیدگاه مرتبط با آن نقش را به کار گیرد. این می‌تواند برای دریافت پاسخ‌های تخصصی در زمینه‌های مختلف مفید باشد.

### پرامپت زمینه‌ای (Contextual Prompting)

پرامپت زمینه‌ای شامل ارائه اطلاعات زمینه‌ای مرتبط به مدل است تا به آن کمک کند پاسخ‌های دقیق‌تر و مرتبط‌تری تولید کند. این زمینه می‌تواند شامل اطلاعات پس‌زمینه، محدودیت‌ها، یا هر داده دیگری باشد که به مدل کمک می‌کند تا درک بهتری از وظیفه داشته باشد.

**مثال پرامپت زمینه‌ای:**

```
زمینه: من یک معلم ریاضی هستم که برای دانش‌آموزان کلاس هفتم تدریس می‌کنم. دانش‌آموزان من با مفهوم کسرها مشکل دارند.

سؤال: چگونه می‌توانم مفهوم جمع و تفریق کسرها را به روشی ساده و جذاب توضیح دهم؟
```

ارائه زمینه به مدل کمک می‌کند تا پاسخی تولید کند که برای موقعیت خاص مناسب‌تر است. در این مثال، زمینه به مدل می‌گوید که پاسخ باید برای دانش‌آموزان کلاس هفتم مناسب باشد و باید بر مشکلات خاصی که با کسرها دارند تمرکز کند.

### پرامپت قدم به عقب (Step-back Prompting)

پرامپت قدم به عقب یک تکنیک است که در آن از مدل خواسته می‌شود قبل از پرداختن به یک مسئله پیچیده، یک قدم به عقب بردارد و مسئله را از دیدگاهی وسیع‌تر یا انتزاعی‌تر در نظر بگیرد. این می‌تواند به مدل کمک کند تا مفاهیم اساسی را درک کند و راه‌حل‌های بهتری ارائه دهد.

**مثال پرامپت قدم به عقب:**

```
قبل از پاسخ به این سؤال، لطفاً یک قدم به عقب برگرد و درباره مفاهیم کلیدی مرتبط با آن فکر کن:
چرا بیت‌کوین ارزشمند است؟
```

این تکنیک به ویژه برای مسائل پیچیده یا چند بعدی مفید است، جایی که یک رویکرد مستقیم ممکن است منجر به پاسخ‌های سطحی یا ناقص شود.

### زنجیره تفکر (Chain of Thought)

زنجیره تفکر (CoT) یک تکنیک قدرتمند است که در آن مدل تشویق می‌شود تا مراحل استدلال خود را قبل از ارائه پاسخ نهایی نشان دهد. این می‌تواند به تولید پاسخ‌های دقیق‌تر، به ویژه برای مسائل پیچیده یا چند مرحله‌ای کمک کند.

**مثال زنجیره تفکر:**

```
مسئله: اگر ۵ کتاب داشته باشم و ۲ کتاب به دوستم قرض بدهم، سپس ۳ کتاب جدید بخرم، در نهایت چند کتاب دارم؟

بیا قدم به قدم فکر کنیم:
```

با درخواست از مدل برای "قدم به قدم فکر کردن"، آن را تشویق می‌کنید تا مراحل استدلال خود را نشان دهد. این می‌تواند به پاسخ‌های دقیق‌تر منجر شود، زیرا مدل مجبور است هر مرحله از فرآیند حل مسئله را در نظر بگیرد.
