<!DOCTYPE html>
<html lang="fa" dir="rtl">

<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>آموزش مهندسی پرامپت (Prompt Engineering)</title>
    <meta name="description" content="آموزش مهندسی پرامپت Prompt Engineering گوگل با نکات و توضیحات اضافی برای درک بهتر مفاهیم. یادگیری تکنیک‌های پرامپت برای مدل‌های زبانی بزرگ.">
    <meta name="keywords" content="مهندسی پرامپت, Prompt Engineering, مدل‌های زبانی بزرگ, LLM, ترجمه کتاب, آموزش پرامپت, تکنیک‌های پرامپت, Google Prompt Engineering">
    <meta name="author" content="Saman Esmaeil">
    <meta property="og:title" content="آموزش مهندسی پرامپت (Prompt Engineering)">
    <meta property="og:description" content="ترجمه کتاب Prompt Engineering گوگل با نکات و توضیحات اضافی برای درک بهتر مفاهیم مهندسی پرامپت.">
    <meta property="og:type" content="website">
    <meta property="og:url" content="https://teal33t.github.io/prompt-engineering">
    <meta property="og:image" content="https://teal33t.github.io/prompt-engineering/images/og-image.png">
    <meta name="twitter:card" content="summary_large_image">    
    <meta name="twitter:title" content="آموزش مهندسی پرامپت (Prompt Engineering)">
    <meta name="twitter:description" content="Prompt Engineering گوگل با نکات و توضیحات اضافی برای درک بهتر مفاهیم مهندسی پرامپت.">
    <meta name="twitter:image" content="https://teal33t.github.io/prompt-engineering/images/og-image.png">
    <style>
        @import url('https://fonts.googleapis.com/css2?family=SUSE:wght@100..800&family=Vazirmatn:wght@100..900&display=swap');
    </style>
    <style>
        body {
            font-family: 'Vazirmatn', sans-serif;
        }

        /* Global styles */
        :root {
            --primary-color: #4285f4;
            --secondary-color: #34a853;
            --accent-color: #ea4335;
            --text-color: #333;
            --light-bg: #f8f9fa;
            --border-color: #e0e0e0;
            --code-bg: #f5f5f5;
            --code-border: #ddd;
            --toc-bg: #f0f4f8;
            --header-bg: #e8f0fe;
        }

        * {
            box-sizing: border-box;
            margin: 0;
            padding: 0;
        }

        body {
            font-family: 'Vazirmatn', 'Arial', sans-serif;
            line-height: 1.6;
            color: var(--text-color);
            background-color: var(--light-bg);
            padding: 0;
            margin: 0;
            text-align: right;
            direction: rtl;
        }

        /* Container styles */
        .container {
            display: flex;
            flex-direction: row-reverse;
            max-width: 1400px;
            margin: 0 auto;
            padding: 0;
            background-color: white;
            box-shadow: 0 0 10px rgba(0, 0, 0, 0.1);
        }

        /* Header styles */
        header {
            background-color: var(--header-bg);
            padding: 2rem 1rem;
            text-align: center;
            border-bottom: 1px solid var(--border-color);
        }

        header h1 {
            margin-bottom: 1rem;
        }

        /* Table of Contents styles */
        .sidebar {
            width: 300px;
            background-color: var(--toc-bg);
            padding: 2rem 1rem;
            position: sticky;
            top: 0;
            height: 100vh;
            overflow-y: auto;
            border-left: 1px solid var(--border-color);
        }

        /* Content styles */
        .content {
            flex: 1;
            padding: 2rem;
            overflow-y: auto;
        }

        /* Typography styles */
        h1 {
            color: var(--primary-color);
            margin-bottom: 1rem;
            font-size: 2.5rem;
        }

        h2 {
            color: var(--primary-color);
            margin: 1.5rem 0 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 2px solid var(--primary-color);
            font-size: 1.8rem;
        }

        h3 {
            color: var(--secondary-color);
            margin: 1.5rem 0 1rem;
            font-size: 1.4rem;
        }

        h4 {
            color: var(--accent-color);
            margin: 1.5rem 0 1rem;
            font-size: 1.2rem;
        }

        p {
            margin-bottom: 1rem;
            text-align: justify;
        }

        /* Link styles */
        a {
            color: var(--primary-color);
            text-decoration: none;
            transition: color 0.2s;
        }

        a:hover {
            color: var(--accent-color);
            text-decoration: underline;
        }

        /* TOC styles */
        .toc {
            list-style-type: none;
            padding: 0;
            margin: 0;
        }

        .toc li {
            margin-bottom: 0.5rem;
        }

        .toc li a {
            display: block;
            padding: 0.5rem;
            border-radius: 4px;
            transition: background-color 0.2s;
        }

        .toc li a:hover {
            background-color: rgba(66, 133, 244, 0.1);
            text-decoration: none;
            color: var(--primary-color);
        }

        .toc-sub {
            list-style-type: none;
            margin-right: 1.5rem;
            margin-top: 0.5rem;
            font-size: 0.9rem;
        }

        /* Code block styles */
        pre {
            background-color: var(--code-bg);
            border-radius: 4px;
            padding: 1rem;
            overflow-x: auto;
            margin: 1rem 0;
            direction: ltr;
            text-align: left;
            border: 1px solid var(--code-border);
        }

        code {
            font-family: 'Courier New', monospace;
            font-size: 0.9rem;
            color: #333;
        }

        /* Section styles */
        .section {
            margin-bottom: 3rem;
            padding-bottom: 1rem;
            border-bottom: 1px solid var(--border-color);
        }

        .section:last-child {
            border-bottom: none;
        }

        /* Table styles */
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 1rem 0;
            overflow-x: auto;
            display: block;
        }

        th,
        td {
            border: 1px solid var(--border-color);
            padding: 0.75rem;
            text-align: right;
        }

        th {
            background-color: var(--toc-bg);
            font-weight: bold;
        }

        tr:nth-child(even) {
            background-color: var(--light-bg);
        }

        /* List styles */
        ul,
        ol {
            margin: 1rem 1.5rem;
        }

        li {
            margin-bottom: 0.5rem;
        }

        /* Responsive design */
        @media (max-width: 992px) {
            .container {
                flex-direction: column;
            }

            .sidebar {
                width: 100%;
                height: auto;
                position: relative;
                border-left: none;
                border-bottom: 1px solid var(--border-color);
            }

            .content {
                padding: 1.5rem;
            }
        }

        @media (max-width: 576px) {
            h1 {
                font-size: 2rem;
            }

            h2 {
                font-size: 1.5rem;
            }

            h3 {
                font-size: 1.2rem;
            }

            .content {
                padding: 1rem;
            }
        }

        code {
            font-family: 'Courier New', monospace;
            background-color: var(--code-bg);
            padding: 0.2rem 0.4rem;
            border-radius: 3px;
            font-size: 0.9rem;
            direction: ltr;
            display: inline-block;
        }

        pre {
            background-color: var(--code-bg);
            border: 1px solid var(--code-border);
            border-radius: 4px;
            padding: 1rem;
            overflow-x: auto;
            margin-bottom: 1.5rem;
            direction: ltr;
        }

        pre code {
            background-color: transparent;
            padding: 0;
            border-radius: 0;
            display: block;
        }

        table {
            width: 100%;
            border-collapse: collapse;
            margin-bottom: 1.5rem;
        }

        th,
        td {
            border: 1px solid var(--border-color);
            padding: 0.75rem;
        }

        th {
            background-color: var(--light-bg);
        }

        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 1.5rem auto;
        }

        blockquote {
            border-right: 4px solid var(--primary-color);
            padding-right: 1rem;
            margin-right: 0;
            margin-left: 0;
            margin-bottom: 1.5rem;
            background-color: var(--light-bg);
            padding: 1rem;
            border-radius: 4px;
        }

        .section {
            margin-bottom: 3rem;
            scroll-margin-top: 2rem;
        }

        @media (max-width: 768px) {
            .container {
                flex-direction: column;
            }

            .sidebar {
                width: 100%;
                height: auto;
                position: relative;
            }

            .content {
                width: 100%;
            }
        }
    </style>
</head>

<body>
    <header>
        <h1>آموزش مهندسی پرامپت (Prompt Engineering)</h1>
        <div style="width: 100%;">ترجمه کتاب Prompt Engineering (Google) با یه سری چیزای اضافی!</div>
        <div style="margin-top: 1rem; display: flex; justify-content: center; gap: 1rem; flex-wrap: wrap; align-items: center;">
            <!-- Twitter Share Button styled like GitHub button -->
            <a href="https://twitter.com/intent/tweet?text=آموزش%20مهندسی%20پرامپت%20(Prompt%20Engineering)&url=https%3A%2F%2Fyourwebsite.com" target="_blank" rel="noopener noreferrer" style="display: inline-block; padding: 0 10px; height: 20px; line-height: 20px; border: 1px solid #d1d5da; border-radius: 6px; background-color: #eff3f6; color: #24292f; font-size: 12px; font-weight: 600; font-family: -apple-system, BlinkMacSystemFont, 'Segoe UI', Helvetica, Arial, sans-serif, 'Apple Color Emoji', 'Segoe UI Emoji'; text-decoration: none; white-space: nowrap;">
                <svg aria-hidden="true" height="16" viewBox="0 0 24 24" version="1.1" width="16" data-view-component="true" fill="#1DA1F2" style="vertical-align: text-bottom; margin-right: 4px;">
                    <path d="M23.954 4.569c-.885.389-1.83.654-2.825.775 1.014-.611 1.794-1.574 2.163-2.723-.949.564-2.005.974-3.127 1.195-.897-.959-2.178-1.559-3.594-1.559-2.723 0-4.928 2.206-4.928 4.928 0 .39.045.765.127 1.124-4.094-.205-7.725-2.165-10.158-5.144-.424.722-.666 1.561-.666 2.457 0 1.69.86 3.179 2.17 4.054-.798-.025-1.55-.245-2.205-.612v.061c0 2.362 1.679 4.332 3.911 4.776-.41.111-.843.171-1.287.171-.314 0-.615-.03-.916-.086.631 1.953 2.445 3.377 4.604 3.417-1.68 1.318-3.809 2.105-6.102 2.105-.395 0-.779-.023-1.17-.067 2.179 1.397 4.768 2.209 7.557 2.209 9.054 0 14-7.496 14-13.986 0-.21 0-.423-.015-.633.962-.689 1.8-1.56 2.46-2.548l-.047-.02z"></path>
                </svg>
                Share on X
            </a>

            <!-- GitHub Star Button -->
            <iframe src="https://ghbtns.com/github-btn.html?user=teal33t&repo=prompt-engineering&type=star&count=true" frameborder="0" scrolling="0" width="100" height="20" title="GitHub"></iframe>
        </div>
    </header>

    <div class="container">
        <div class="sidebar">
            <h2>فهرست مطالب</h2>
            <ul class="toc">
                <li><a href="#مقدمه">1. مقدمه</a></li>
                <li><a href="#مفهوم-مهندسی-پرامپت">2. مفهوم مهندسی پرامپت</a></li>
                <li>
                    <a href="#تنظیمات-خروجی-مدلهای-زبانی-بزرگ">3. تنظیمات خروجی مدل‌های زبانی بزرگ</a>
                    <ul class="toc-sub">
                        <li><a href="#طول-خروجی">طول خروجی</a></li>
                        <li><a href="#کنترلهای-نمونهبرداری">کنترل‌های سمپلینگ</a></li>
                        <li><a href="#دما-temperature">دما (Temperature)</a></li>
                        <li><a href="#top-k-و-top-p">Top-K و Top-P</a></li>
                        <li><a href="#ترکیب-تنظیمات">ترکیب تنظیمات</a></li>
                    </ul>
                </li>
                <li>
                    <a href="#تکنیکهای-مهندسی-پرامپت">4. تکنیک‌های مهندسی پرامپت</a>
                    <ul class="toc-sub">
                        <li><a href="#پرامپت-زیرو-شات-zero-shot">پرامپت زیرو-شات (Zero-shot)</a></li>
                        <li><a href="#پرامپت-تک-شات-و-چند-شات-one-shot--few-shot">پرامپت تک-شات و چند-شات (One-shot &
                                Few-shot)</a></li>
                        <li><a href="#پرامپت-سیستمی-system-prompting">پرامپت سیستمی (System Prompting)</a></li>
                        <li><a href="#پرامپت-نقش-role-prompting">پرامپت نقش (Role Prompting)</a></li>
                        <li><a href="#پرامپت-زمینهای-contextual-prompting">پرامپت زمینه‌ای (Contextual Prompting)</a>
                        </li>
                        <li><a href="#پرامپت-قدم-به-عقب-step-back-prompting">پرامپت استپ‌بک (Step-back Prompting)</a>
                        </li>
                        <li><a href="#زنجیره-تفکر-chain-of-thought">زنجیره تفکر (Chain of Thought)</a></li>
                        <li><a href="#خودسازگاری-self-consistency">خودسازگاری (Self-consistency)</a></li>
                        <li><a href="#درخت-تفکرات-tree-of-thoughts">درخت تفکرات (Tree of Thoughts)</a></li>
                        <li><a href="#واکنش-react">Reason & Action (ReAct)</a></li>
                    </ul>
                </li>
                <li>
                    <a href="#پرامپت-برای-کدنویسی">5. پرامپت برای کدنویسی</a>
                    <ul class="toc-sub">
                        <li><a href="#نوشتن-کد">نوشتن کد</a></li>
                        <li><a href="#توضیح-کد">توضیح کد</a></li>
                        <li><a href="#ترجمه-کد">ترجمه کد</a></li>
                        <li><a href="#اشکالزدایی-و-بررسی-کد">اشکال‌زدایی و بررسی کد</a></li>
                    </ul>
                </li>
                <li>
                    <a href="#بهترین-شیوههای-مهندسی-پرامپت">6. بهترین شیوه‌های مهندسی پرامپت</a>
                    <ul class="toc-sub">
                        <li><a href="#ارائه-مثالها">ارائه مثال‌ها</a></li>
                        <li><a href="#طراحی-با-سادگی">طراحی با سادگی</a></li>
                        <li><a href="#مشخص-کردن-خروجی">مشخص کردن خروجی</a></li>
                        <li><a href="#استفاده-از-دستورالعملها-به-جای-محدودیتها">استفاده از دستورالعمل‌ها به جای
                                محدودیت‌ها</a></li>
                        <li><a href="#کنترل-طول-توکن">کنترل طول توکن</a></li>
                        <li><a href="#استفاده-از-متغیرها-در-پرامپتها">استفاده از متغیرها در پرامپت‌ها</a></li>
                        <li><a href="#آزمایش-با-فرمتهای-ورودی-و-سبکهای-نوشتاری">آزمایش با فرمت‌های ورودی و سبک‌های
                                نوشتاری</a></li>
                        <li><a href="#بهترین-شیوههای-زنجیره-تفکر">بهترین شیوه‌های زنجیره تفکر (CoT)</a></li>
                        <li><a href="#مستندسازی-تلاشهای-مختلف-پرامپت">مستندسازی تلاش‌های مختلف پرامپت</a></li>
                    </ul>
                </li>
                <li><a href="#نمونه-کاربردهای-عملی">7. نمونه کاربردهای عملی</a></li>
                <li><a href="#جمعبندی">8. جمع‌بندی</a></li>
            </ul>
        </div>

        <div class="content">
            <!-- Content will be filled in the next step -->

            <div id="books-download" class="section">
                <h2>دانلود کتاب‌ها</h2>
                <p>در این بخش می‌توانید کتاب‌های مرتبط را دانلود کنید:</p>
                <ul dir="ltr" style="text-align: left;">
                    <li><a target="_blank" href="books/2025_Google_Prompt_Engineering_v7.pdf" download>Google Prompt Engineering (2025)</a> 🔹 </li>
                    <li><a target="_blank" href="books/2025_How_to_Become_a_Prompt_God.pdf" download>How to Become a Prompt God: Mastering Advanced Prompt Engineering For AI (2025)</a></li>
                    <li><a target="_blank" href="books/2025_Prompt_Engineering_for_Generative_AI.pdf" download>Prompt Engineering for GenerativeAI (2024)</a></li>
                </ul>
            </div>

            <div id="مقدمه" class="section">
                <h2>1. مقدمه</h2>

                <p>
                    هنگام فکر کردن درباره ورودی و خروجی یک مدل زبانی بزرگ (LLM)، یک دستور متنی، ورودی‌ای است که مدل برای
                    پیش‌بینی یک خروجی خاص استفاده می‌کند.
                </p>

                <h4>
                    شما نیازی نیست یک دانشمند داده یا مهندس یادگیری ماشین باشید - هر کسی می‌تواند یک پرامپت بنویسد.
                </h4>

                <p>
                    با این حال، ساخت موثرترین پرامپت می‌تواند پیچیده باشد. جنبه‌های مختلفی از پرامپت شما بر کارآمدی آن
                    تأثیر می‌گذارد، مثل مدلی که استفاده می‌کنید، داده‌های آموزشی مدل، تنظیمات مدل، انتخاب کلمات شما، سبک
                    و لحن، ساختار کانتکس همگی مهم هستند. بنابراین، مهندسی پرامپت یک فرآیند تکرار‌شونده است. پرامپت‌های
                    نامناسب می‌توانند منجر به پاسخ‌های مبهم و نادرست شوند و می‌توانند توانایی مدل برای ارائه خروجی
                    معنادار را مختل کنند.
                </p>

                <p>وقتی با چت‌بات Gemini صحبت می‌کنید، اساساً پرامپت‌ها را می‌نویسید، اما این مقاله بر نوشتن پرامپت‌ها
                    برای مدل Gemini در Vertex AI یا با استفاده از API تمرکز دارد، زیرا با پرامپت کردن مستقیم مدل، شما به
                    تنظیمات مانند دما و غیره دسترسی خواهید داشت.</p>

                <p>این مقاله به طور مفصل درباره مهندسی پرامپت بحث می‌کند. ما به تکنیک‌های مختلف پرامپت نگاه خواهیم کرد
                    تا به شما در شروع کار کمک کنیم و نکات و بهترین شیوه‌ها را به اشتراک می‌گذاریم تا یک متخصص پرامپت
                    شوید. همچنین برخی از چالش‌هایی که ممکن است هنگام ساخت پرامپت‌ها با آن‌ها مواجه شوید را بررسی خواهیم
                    کرد.</p>
            </div>

            <div id="مفهوم-مهندسی-پرامپت" class="section">
                <h2>2. مفهوم مهندسی پرامپت</h2>
                <p>به یاد داشته باشید که یک LLM چگونه کار می‌کند؛ این یک موتور پیش‌بینی است. مدل متن متوالی را به عنوان
                    ورودی می‌گیرد و سپس پیش‌بینی می‌کند که توکن بعدی چه باید باشد، بر اساس داده‌هایی که با آن‌ها آموزش
                    دیده است. LLM برای انجام این کار بارها و بارها عملیاتی می‌شود، با افزودن توکن پیش‌بینی شده قبلی به
                    انتهای متن متوالی برای پیش‌بینی توکن بعدی. پیش‌بینی توکن بعدی بر اساس رابطه بین آنچه در توکن‌های
                    قبلی است و آنچه LLM در طول آموزش خود دیده است، انجام می‌شود.</p>

                <p>وقتی یک پرامپت می‌نویسید، در تلاش هستید تا LLM را برای پیش‌بینی توالی درست توکن‌ها تنظیم کنید. مهندسی
                    پرامپت فرآیند طراحی پرامپت‌های با کیفیت بالا است که LLM‌ها را برای تولید خروجی‌های دقیق هدایت
                    می‌کند. این فرآیند شامل آزمایش برای یافتن بهترین پرامپت، بهینه‌سازی طول پرامپت و ارزیابی سبک نوشتاری
                    و ساختار یک پرامپت در رابطه با وظیفه است. در زمینه پردازش زبان طبیعی و LLM‌ها، یک پرامپت ورودی‌ای
                    است که به مدل ارائه می‌شود تا پاسخ یا پیش‌بینی را تولید کند.</p>

                <p>این پرامپت‌ها می‌توانند برای دستیابی به انواع مختلفی از وظایف درک و تولید مانند خلاصه‌سازی متن،
                    استخراج اطلاعات، پرسش و پاسخ، طبقه‌بندی متن، ترجمه زبان یا کد، تولید کد و مستندسازی کد یا استدلال
                    استفاده شوند.</p>

                <p>لطفاً به راهنماهای پرامپت Google با مثال‌های ساده و موثر پرامپت مراجعه کنید.</p>

                <p>هنگام مهندسی پرامپت، با انتخاب یک مدل شروع خواهید کرد. ممکن است نیاز باشد پرامپت‌ها برای مدل خاص شما
                    بهینه شوند، صرف نظر از اینکه از مدل‌های زبانی Gemini در Vertex AI، GPT، Claude یا یک مدل منبع باز
                    مانند Gemma یا LLaMA استفاده می‌کنید.</p>

                <p>علاوه بر پرامپت، شما همچنین نیاز به آزمایش با تنظیمات مختلف یک LLM خواهید داشت.</p>
            </div>

            <div id="تنظیمات-خروجی-مدلهای-زبانی-بزرگ" class="section">
                <h2>3. تنظیمات خروجی مدل‌های زبانی بزرگ</h2>
                <p>پس از انتخاب مدل، باید تنظیمات مدل را مشخص کنید. اکثر LLM‌ها با گزینه‌های تنظیم مختلفی ارائه می‌شوند
                    که خروجی LLM را کنترل می‌کنند. مهندسی پرامپت موثر نیازمند تنظیم بهینه این پیکربندی‌ها برای وظیفه شما
                    است.</p>

                <div id="طول-خروجی" class="section">
                    <h3>طول خروجی</h3>
                    <p>یک تنظیم مهم، تعداد توکن‌هایی است که در یک پاسخ تولید می‌شوند. تولید توکن‌های بیشتر نیازمند
                        محاسبات بیشتری از LLM است، که منجر به مصرف انرژی بالاتر، زمان‌های پاسخ احتمالاً کندتر و
                        هزینه‌های بالاتر می‌شود.</p>

                    <p>کاهش طول خروجی LLM باعث نمی‌شود که LLM از نظر سبک یا متنی در خروجی که ایجاد می‌کند مختصرتر شود،
                        فقط باعث می‌شود که LLM پس از رسیدن به محدودیت، پیش‌بینی توکن‌های بیشتر را متوقف کند. اگر نیازهای
                        شما به طول خروجی کوتاه نیاز دارد، احتمالاً باید پرامپت خود را نیز برای تطبیق با آن مهندسی کنید.
                    </p>

                    <p>محدودیت طول خروجی به ویژه برای برخی از تکنیک‌های پرامپت LLM، مانند ReAct، مهم است، جایی که LLM پس
                        از پاسخی که می‌خواهید، به انتشار توکن‌های بی‌فایده ادامه خواهد داد.</p>

                    <p>توجه داشته باشید، تولید توکن‌های بیشتر نیازمند محاسبات بیشتری از LLM است، که منجر به مصرف انرژی
                        بالاتر و زمان‌های پاسخ احتمالاً کندتر می‌شود، که منجر به هزینه‌های بالاتر می‌شود.</p>
                </div>

                <div id="کنترلهای-نمونهبرداری" class="section">
                    <h3>کنترل‌های سمپلینگ</h3>
                    <p>LLM‌ها رسماً یک توکن واحد را پیش‌بینی نمی‌کنند. در عوض، LLM‌ها احتمالات را برای اینکه توکن بعدی
                        چه می‌تواند باشد پیش‌بینی می‌کنند، با هر توکن در واژگان LLM که یک احتمال دریافت می‌کند. سپس از
                        آن احتمالات توکن سمپلینگ می‌شود تا مشخص شود توکن بعدی تولید شده چه خواهد بود.</p>

                    <p>دما (Temperature)، Top-K و Top-P رایج‌ترین تنظیمات پیکربندی هستند که تعیین می‌کنند چگونه احتمالات
                        توکن پیش‌بینی شده برای انتخاب یک توکن خروجی واحد پردازش می‌شوند.</p>
                </div>

                <div id="دما-temperature" class="section">
                    <h3>دما (Temperature)</h3>
                    <p>دما درجه تصادفی بودن در انتخاب توکن را کنترل می‌کند. دماهای پایین‌تر برای پرامپت‌هایی که انتظار
                        پاسخ قطعی‌تری دارند مناسب هستند، در حالی که دماهای بالاتر می‌توانند منجر به نتایج متنوع‌تر یا
                        غیرمنتظره شوند. دمای 0 (greedy decoding) قطعیت را نشان میدهد: توکن با بالاترین احتمال همیشه
                        انتخاب می‌شود (اگرچه توجه داشته باشید که اگر دو توکن دارای همان بالاترین احتمال پیش‌بینی شده
                        باشند، بسته به نحوه پیاده‌سازی شکستن تساوی، ممکن است همیشه با دمای 0 خروجی یکسانی دریافت نکنید).
                    </p>

                    <p>دماهای نزدیک به حداکثر تمایل به ایجاد خروجی تصادفی‌تر دارند. و همانطور که دما بالاتر و بالاتر
                        می‌رود، همه توکن‌ها به طور یکسان احتمال دارند که توکن پیش‌بینی شده بعدی باشند.</p>

                    <p>کنترل دمای Gemini را می‌توان به روشی مشابه با تابع softmax که در یادگیری ماشین استفاده می‌شود درک
                        کرد. تنظیم دمای پایین، دمای پایین softmax (T) را منعکس می‌کند، که بر یک دمای ترجیحی واحد با
                        قطعیت بالا تأکید می‌کند. تنظیم دمای بالاتر Gemini مانند دمای بالای softmax است، که طیف وسیع‌تری
                        از دماها در اطراف تنظیم انتخاب شده را قابل قبول‌تر می‌کند. این عدم قطعیت افزایش یافته،
                        سناریوهایی را در نظر می‌گیرد که در آن یک دمای دقیق و سختگیرانه ممکن است ضروری نباشد، مانند زمانی
                        که با خروجی‌های خلاقانه آزمایش می‌کنید.</p>
                </div>

                <div id="top-k-و-top-p" class="section">
                    <h3>Top-K و Top-P</h3>
                    <p>Top-K و Top-P دو تنظیم سمپلینگ هستند که در LLM‌ها استفاده می‌شوند تا توکن بعدی پیش‌بینی شده را از
                        توکن‌هایی با بالاترین احتمالات پیش‌بینی شده محدود کنند. مانند دما، این تنظیمات سمپلینگ، تصادفی
                        بودن و تنوع متن تولید شده را کنترل می‌کنند.</p>
                    <ul>
                        <li>سمپلینگ Top-K، K توکن با بیشترین احتمال را از توزیع پیش‌بینی شده مدل انتخاب می‌کند. هرچه
                            Top-K بالاتر باشد، خروجی مدل خلاقانه‌تر و متنوع‌تر است؛ هرچه Top-K پایین‌تر باشد، خروجی مدل
                            محدودتر و واقعی‌تر است. Top-K برابر با 1 معادل greedy decoding است.</li>

                        <li>سمپلینگ Top-P، توکن‌های برتری را انتخاب می‌کند که احتمال تجمعی آن‌ها از یک مقدار خاص (P)
                            تجاوز نکند. مقادیر برای P از 0 تا 1 (تمام توکن‌ها در واژگان LLM) متغیر است.</li>
                    </ul>
                    <p>بهترین راه برای انتخاب بین Top-K و Top-P، آزمایش با هر دو روش (یا هر دو با هم) و دیدن اینکه کدام
                        یک نتایجی را که به دنبال آن هستید تولید می‌کند.</p>
                </div>

                <div id="ترکیب-تنظیمات" class="section">
                    <h3>ترکیب تنظیمات</h3>
                    <p>انتخاب بین Top-K، Top-P، دما و تعداد توکن‌هایی که باید تولید شوند، به کاربرد خاص و نتیجه مورد نظر
                        بستگی دارد، و تنظیمات همگی بر یکدیگر تأثیر می‌گذارند. همچنین مهم است که مطمئن شوید درک می‌کنید
                        که مدل انتخابی شما چگونه تنظیمات سمپلینگ مختلف را با هم ترکیب می‌کند.</p>

                    <p>اگر دما، Top-K و Top-P همگی در دسترس باشند (مانند Vertex Studio)، توکن‌هایی که هم معیارهای Top-K
                        و هم Top-P را برآورده می‌کنند، نامزدهایی برای توکن پیش‌بینی شده بعدی هستند، و سپس دما برای
                        سمپلینگ از توکن‌هایی که از معیارهای Top-K و Top-P عبور کرده‌اند اعمال می‌شود. اگر فقط Top-K یا
                        Top-P در دسترس باشد، رفتار یکسان است اما فقط از یک تنظیم Top-K یا P استفاده می‌شود.</p>

                    <p>اگر دما در دسترس نباشد، از هر توکنی که معیارهای Top-K و/یا Top-P را برآورده می‌کند، به صورت
                        تصادفی انتخاب می‌شود تا یک توکن پیش‌بینی شده بعدی واحد تولید شود.</p>

                    <p>در تنظیمات افراطی یک مقدار پیکربندی سمپلینگ، آن تنظیم سمپلینگ یا تنظیمات پیکربندی دیگر را لغو
                        می‌کند یا بی‌اهمیت می‌شود.</p>
                    <ul>
                        <li>اگر دما را روی 0 تنظیم کنید، Top-K و Top-P بی‌اهمیت می‌شوند - توکن با بیشترین احتمال، توکن
                            پیش‌بینی شده بعدی می‌شود. اگر دما را به شدت بالا تنظیم کنید (بالای 1 - عموماً به 10ها)، دما
                            بی‌اهمیت می‌شود و از هر توکنی که از معیارهای Top-K و/یا Top-P عبور می‌کند، به صورت تصادفی
                            سمپلینگ می‌شود تا یک توکن پیش‌بینی شده بعدی انتخاب شود.</li>

                        <li>اگر Top-K را روی 1 تنظیم کنید، دما و Top-P بی‌اهمیت می‌شوند. فقط یک توکن از معیارهای Top-K
                            عبور می‌کند، و آن توکن، توکن پیش‌بینی شده بعدی است. اگر Top-K را به شدت بالا تنظیم کنید،
                            مانند اندازه واژگان LLM، هر توکن با احتمال غیر صفر برای اینکه توکن بعدی باشد، معیارهای Top-K
                            را برآورده می‌کند و هیچ کدام انتخاب نمی‌شوند.</li>

                        <li>اگر Top-P را روی 0 (یا یک مقدار بسیار کوچک) تنظیم کنید، اکثر پیاده‌سازی‌های سمپلینگ LLM فقط
                            توکن با بیشترین احتمال را در نظر می‌گیرند تا معیارهای Top-P را برآورده کند، که دما و Top-K
                            را بی‌اهمیت می‌کند. اگر Top-P را روی 1 تنظیم کنید، هر توکن با احتمال غیر صفر برای اینکه توکن
                            بعدی باشد، معیارهای Top-P را برآورده می‌کند، و هیچ کدام انتخاب نمی‌شوند.</li>
                    </ul>
                    <p>به عنوان یک نقطه شروع کلی، دمای 0.2، Top-P برابر با 0.95 و Top-K برابر با 30 به شما نتایج نسبتاً
                        منسجمی می‌دهد که می‌تواند خلاقانه باشد اما نه به طور افراطی. اگر می‌خواهید نتایج به ویژه
                        خلاقانه‌ای داشته باشید، سعی کنید با دمای 0.9، Top-P برابر با 0.99 و Top-K برابر با 40 شروع کنید.
                        و اگر می‌خواهید نتایج کمتر خلاقانه‌ای داشته باشید، سعی کنید با دمای 0.1، Top-P برابر با 0.9 و
                        Top-K برابر با 20 شروع کنید. در نهایت، اگر وظیفه شما همیشه یک پاسخ صحیح واحد دارد (مثلاً، پاسخ
                        به یک مسئله ریاضی)، با دمای 0 شروع کنید.</p>

                    <p>توجه: با آزادی بیشتر (دما، Top-K، Top-P و توکن‌های خروجی بالاتر)، LLM ممکن است متنی تولید کند که
                        کمتر مرتبط است.</p>

                    <p>هشدار: آیا تا به حال پاسخی را دیده‌اید که با مقدار زیادی کلمات پرکننده به پایان برسد؟ این همچنین
                        به عنوان "باگ حلقه تکرار" شناخته می‌شود، که یک مشکل رایج در مدل‌های زبانی بزرگ است که در آن مدل
                        در یک چرخه گیر می‌کند، به طور مکرر همان کلمه (پرکننده)، عبارت یا ساختار جمله را تولید می‌کند، که
                        اغلب با تنظیمات نامناسب دما و top-k/top-p تشدید می‌شود. این می‌تواند هم در تنظیمات دمای پایین و
                        هم بالا رخ دهد، اگرچه به دلایل مختلف. در دماهای پایین، مدل بیش از حد قطعی می‌شود، به شدت به مسیر
                        با بالاترین احتمال می‌چسبد، که می‌تواند منجر به یک حلقه شود اگر آن مسیر به متن تولید شده قبلی
                        بازگردد. برعکس، در دماهای بالا، خروجی مدل بیش از حد تصادفی می‌شود، احتمال اینکه یک کلمه یا عبارت
                        انتخاب شده به طور تصادفی، به شانس، به یک حالت قبلی بازگردد را افزایش می‌دهد، که به دلیل تعداد
                        زیاد گزینه‌های موجود، یک حلقه ایجاد می‌کند. در هر دو مورد، فرآیند سمپلینگ مدل "گیر می‌کند"، که
                        منجر به خروجی یکنواخت و بی‌فایده می‌شود تا زمانی که پنجره خروجی پر شود. حل این مشکل اغلب نیازمند
                        تنظیم دقیق مقادیر دما و top-k/top-p برای یافتن تعادل بهینه بین قطعیت و تصادفی بودن است.</p>
                </div>
            </div>

            <div id="تکنیکهای-مهندسی-پرامپت" class="section">
                <h2>4. تکنیک‌های مهندسی پرامپت</h2>
                <p>مدل‌های زبانی بزرگ (LLM) برای پیروی از دستورالعمل‌ها تنظیم شده‌اند و روی مقادیر زیادی از داده‌ها
                    آموزش دیده‌اند تا بتوانند یک پرامپت را درک کنند و پاسخی تولید کنند. اما LLM‌ها کامل نیستند؛ هرچه متن
                    پرامپت شما واضح‌تر باشد، برای LLM بهتر است تا متن بعدی محتمل را پیش‌بینی کند. علاوه بر این،
                    تکنیک‌های خاصی که از نحوه آموزش LLM‌ها و نحوه کار آن‌ها استفاده می‌کنند، به شما کمک می‌کنند تا نتایج
                    مرتبط را از LLM‌ها دریافت کنید.</p>

                <p>حال که درک می‌کنیم مهندسی پرامپت چیست و چه چیزی نیاز دارد، بیایید به برخی از مثال‌های مهم‌ترین
                    تکنیک‌های پرامپت بپردازیم.</p>

                <div id="پرامپت-زیرو-شات-zero-shot" class="section">
                    <h3>پرامپت زیرو-شات (Zero-shot)</h3>
                    <p>یک پرامپت زیرو-شات ساده‌ترین نوع پرامپت است. که فقط توصیفی از یک وظیفه و برخی متن‌ها را برای
                        شروع کار LLM ارائه می‌دهد. این ورودی می‌تواند هر چیزی باشد: یک سؤال، شروع یک داستان، یا
                        دستورالعمل‌ها. نام زیرو-شات به معنای 'بدون مثال' است.</p>

                    <p>بیایید از Vertex AI Studio (برای زبان) در Vertex AI استفاده کنیم، که یک محیط آزمایشی برای تست
                        پرامپت‌ها ارائه می‌دهد. در جدول 1، یک مثال پرامپت زیرو-شات برای طبقه‌بندی نقدهای فیلم خواهید
                        دید.</p>

                    <p>فرمت جدول که در زیر استفاده شده است، روش عالی برای مستندسازی پرامپت‌ها است. پرامپت‌های شما
                        احتمالاً قبل از اینکه در یک کد قرار بگیرند، از چندین تکرار عبور خواهند کرد، بنابراین مهم است که
                        کار مهندسی پرامپت خود را به روشی منظم و ساختاریافته پیگیری کنید. اطلاعات بیشتر در مورد این فرمت
                        جدول، اهمیت پیگیری کار مهندسی پرامپت و فرآیند توسعه پرامپت در بخش بهترین شیوه‌ها در ادامه این
                        فصل ("مستندسازی تلاش‌های مختلف پرامپت") آمده است.</p>

                    <p>دمای مدل باید روی عدد پایینی تنظیم شود، زیرا نیازی به خلاقیت نیست، و ما از مقادیر پیش‌فرض Top-K و
                        Top-P مدل gemini-pro استفاده می‌کنیم، که به طور مؤثر هر دو تنظیم را غیرفعال می‌کند (به 'تنظیمات
                        خروجی LLM' در بالا مراجعه کنید). به خروجی تولید شده توجه کنید. کلمات "disturbing" و
                        "masterpiece" باید پیش‌بینی را کمی پیچیده‌تر کنند، زیرا هر دو کلمه در یک جمله استفاده شده‌اند.
                    </p>

                    <p><strong>مثال پرامپت زیرو-شات:</strong></p>

                    <img src="images/zero-shot.png" width="700" />

                    <p>وقتی زیرو-شات کار نمی‌کند، می‌توانید نمونه‌ها یا مثال‌هایی را در پرامپت ارائه دهید، که منجر به
                        پرامپت "تک-شات" و "چند-شات" می‌شود.</p>
                </div>

                <div id="پرامپت-تک-شات-و-چند-شات-one-shot--few-shot" class="section">
                    <h3>پرامپت تک-شات و چند-شات (One-shot & Few-shot)</h3>
                    <p>هنگام ایجاد پرامپت‌ها برای مدل‌های هوش مصنوعی، ارائه مثال‌ها مفید است. این مثال‌ها می‌توانند به
                        مدل کمک کنند تا آنچه را که از آن می‌خواهید درک کند. مثال‌ها به ویژه زمانی مفید هستند که
                        می‌خواهید مدل را به سمت یک ساختار یا الگوی خروجی خاص هدایت کنید.</p>

                    <p>یک پرامپت تک-شات، یک مثال واحد ارائه می‌دهد، از این رو نام تک-شات. ایده این است که مدل مثالی دارد
                        که می‌تواند از آن تقلید کند تا بهترین عملکرد را در انجام وظیفه داشته باشد.</p>

                    <p>یک پرامپت چند-شات چندین مثال ارائه می‌دهد. این به مدل کمک می‌کند تا الگوها را بهتر درک کند و
                        پاسخ‌های دقیق‌تری تولید کند.</p>


                    <p><strong>مثال پرامپت چند-شات:</strong></p>

                    <img src="images/few-one-shot1.png" width="700" />
                    <img src="images/few-one-shot2.png" width="700" />
                    <p>
                        System، Context و Role Prompting همگی تکنیک‌هایی هستند که برای هدایت نحوه تولید متن توسط مدل‌های
                        زبانی بزرگ (LLMs) استفاده می‌شوند، اما هر کدام روی جنبه‌های متفاوتی تمرکز دارند:
                    </p>
                    <p>
                    <ul>
                        <li>
                            System Prompting:
                            این تکنیک، کانتکس کلی و هدف اصلی را برای مدل زبانی مشخص می‌کند. به زبان ساده، مثل این است که
                            به مدل بگوییم «قراره چی کار کنی». مثلاً بهش می‌گیم که باید یک متن رو ترجمه کنه، یا یک نظر رو
                            دسته‌بندی کنه. این یه تصویر بزرگ از وظیفه مدل بهش می‌ده.
                        </li>
                        <li>
                            Contextual Prompting:
                            این تکنیک، جزئیات خاص یا اطلاعات پس‌زمینه‌ای رو که به موضوع یا وظیفه فعلی مربوط می‌شه، به
                            مدل می‌ده. مثلاً اگه ازش سوالی پرسیده بشه، این اطلاعات به مدل کمک می‌کنه بفهمه دقیقاً چی
                            خواسته شده و جوابش رو بر اساس اون تنظیم کنه.
                        </li>
                        <li>
                            Role Prompting:
                            اینجا به مدل یک شخصیت یا هویت خاص می‌دیم که طبق اون رفتار کنه. مثلاً می‌گیم «تو یه معلم
                            هستی» یا «مثل یه دوست حرف بزن». این کار باعث می‌شه جواب‌هایی که مدل می‌ده، با اون نقش و دانش
                            و رفتاری که براش تعریف کردیم، هم‌خونی داشته باشه.
                        </li>
                    </ul>
                    <p>
                        شباهت‌ها و تفاوت‌ها بین System، Contextual و Role Prompting ممکنه هم‌پوشانی زیادی وجود داشته
                        باشه. مثلاً یه دستوری که به مدل یه نقش می‌ده (مثل «تو یه مترجم باش»)، می‌تونه همزمان زمینه‌ای هم
                        داشته باشه (مثل «این متن رو از فارسی به انگلیسی ترجمه کن»). ولی هر کدوم یه هدف اصلی متفاوت دارن:
                    </p>
                    </p>
                </div>

                <div id="پرامپت-سیستمی-system-prompting" class="section">
                    <h3>پرامپت سیستمی (System Prompting)</h3>
                    <p>پرامپت سیستمی یک روش برای تنظیم رفتار کلی مدل است. این به شما اجازه می‌دهد تا به مدل بگویید چه
                        نوع دستیاری باشد، چگونه پاسخ دهد، و چه محدودیت‌هایی داشته باشد.</p>

                    <p><strong>مثال پرامپت سیستمی:</strong></p>

                    <img src="images/system-prompt.png" width="700" />
                    <img src="images/system-prompt2.png" width="700" />

                </div>

                <div id="پرامپت-نقش-role-prompting" class="section">
                    <h3>پرامپت نقش (Role Prompting)</h3>
                    <p>در پرامپت نقش، از مدل می‌خواهید نقش خاصی را بپذیرد. این می‌تواند به تولید پاسخ‌های تخصصی‌تر و
                        متمرکزتر کمک کند.</p>

                    <p><strong>مثال پرامپت نقش:</strong></p>

                    <img src="images/role-prompt.png" width="700" />

                    <img src="images/role-prompt2.png" width="700" />
                </div>

                <div id="پرامپت-زمینهای-contextual-prompting" class="section">
                    <h3>پرامپت کانتکسچوال (Contextual Prompting)</h3>
                    <p>پرامپت کانتکسچوال شامل ارائه اطلاعات زمینه‌ای اضافی به مدل است تا به آن کمک کند پاسخ‌های دقیق‌تر
                        و مرتبط‌تری تولید کند.</p>

                    <p><strong>مثال پرامپت Contextual:</strong></p>


                    <img src="images/contextual-prompt.png" width="700" />

                </div>

                <div id="پرامپت-قدم-به-عقب-step-back-prompting" class="section">
                    <h3>پرامپت استپ‌بک (Step-back Prompting)</h3>
                    <p>
                        پرامپت استپ‌بک (Step-Back Prompting) یک تکنیک برای بهبود عملکرد مدل‌های زبانی بزرگ (LLMs) است.
                        در این روش، ابتدا به مدل یک سوال کلی مرتبط با وظیفه خاص داده می‌شود. سپس پاسخ این سوال کلی
                        به‌عنوان ورودی به یک درخواست بعدی برای انجام وظیفه خاص داده می‌شود. این گام به عقب به مدل اجازه
                        می‌دهد تا دانش پس‌زمینه مرتبط و فرآیندهای استدلالی را فعال کند، قبل از اینکه بخواهد مسئله خاص را
                        حل کند.
                    </p>
                    <p>
                        با در نظر گرفتن اصول کلی و زیربنایی، مدل‌های زبانی می‌توانند پاسخ‌هایی دقیق‌تر و عمیق‌تر تولید
                        کنند. پرامپت استپ‌بک مدل را تشویق می‌کند تا به‌صورت انتقادی فکر کند و دانش خودش را به روش‌های
                        جدید و خلاقانه به کار ببرد. این روش باعث می‌شود درخواست نهایی که وظیفه را انجام می‌دهد، از دانش
                        بیشتری در پارامترهای مدل استفاده کند، در مقایسه با زمانی که مدل مستقیماً با یک درخواست خاص
                        روبه‌رو می‌شود.
                    </p>
                    <p>
                        همچنین، این روش می‌تواند به کاهش سوگیری‌ها در پاسخ‌های مدل کمک کند، چون به‌جای تمرکز روی جزئیات
                        خاص، روی اصول کلی متمرکز می‌شود.
                    </p>
                    <p>
                        مثال‌ها برای درک بهتر
                        برای فهم بهتر اینکه چطور پرامپت استپ‌بک می‌تواند نتایج را بهبود بدهد، بیایم چند مثال رو بررسی
                        کنیم. ابتدا یک درخواست سنتی (جدول 8) رو نگاه می‌کنیم و بعد اون رو با یک درخواست استپ‌بک (جدول 9)
                        مقایسه می‌کنیم.
                    </p>

                    <p><strong>مثال پرامپت استپ‌بک:</strong></p>


                    <img src="images/step-back.png" width="700" />

                    <p>
                        وقتی دما (Temperature) رو روی 1 تنظیم می‌کنید، ممکنه برای یه خط داستانی کلی نوشته‌های خلاقانه‌ای
                        به دست بیارید، ولی این نوشته‌ها معمولاً تصادفی و کلی هستند.
                    </p>

                    <img src="images/step-back01.png" width="700" />
                    <p>
                        آره، این موضوعات به نظر می‌رسه برای یه بازی ویدیویی اول‌شخص مناسب باشن. بیایم برگردیم به درخواست
                        قبلی، ولی این بار پاسخ سوال استپ‌بک رو به‌عنوان زمینه (Context) اضافه کنیم و ببینیم چی
                        برمی‌گردونه
                    </p>
                    <img src="images/step-back02.png" width="700" />
                    <p>
                        این شبیه یه بازی ویدیویی جالب به نظر می‌رسه! با استفاده از تکنیک‌های درخواست‌نویسی استپ‌بک
                        می‌تونید دقت درخواست‌هاتون رو بالاتر ببرید
                    </p>
                </div>

                <div id="زنجیره-تفکر-chain-of-thought" class="section">
                    <h3>زنجیره تفکر (Chain of Thought)</h3>
                    <p>
                        زنجیره تفکر (CoT) تکنیکی است که توانایی استدلال مدل‌های زبانی بزرگ (LLMs) را با تولید گام‌های
                        استدلالی میانی بهبود می‌دهد. این روش به مدل کمک می‌کند تا پاسخ‌های دقیق‌تری تولید کند. می‌توانید
                        CoT را با پرامپت Few-Shot ترکیب کنید تا در وظایف پیچیده‌تر که نیاز به استدلال قبل از پاسخ دارند،
                        نتایج بهتری بگیرید.
                    </p>
                    <p><strong>مزایای CoT:</strong></p>

                    <ul>
                        <li>
                            تلاش کم، تأثیر زیاد: این روش خیلی مؤثره و نیازی به تنظیم دقیق (Finetuning) مدل ندارد، یعنی
                            با مدل‌های آماده (Off-the-Shelf LLMs) به‌خوبی کار می‌کند.
                        </li>
                        <li>
                            شفافیت و تفسیرپذیری: با CoT می‌توانید از پاسخ‌های مدل یاد بگیرید و گام‌های استدلالی که دنبال
                            کرده را ببینید. اگه مشکلی پیش بیاد، می‌تونید اون رو پیدا کنید.
                        </li>
                        <li>

                            پایداری بین نسخه‌ها: به نظر می‌رسد CoT باعث می‌شود وقتی از نسخه‌های مختلف مدل‌های زبانی
                            استفاده می‌کنید، عملکرد درخواست شما کمتر تغییر کند. یعنی درخواست‌هایی که از زنجیره تفکر
                            استفاده می‌کنند، نسبت به درخواست‌های بدون استدلال، بین مدل‌های مختلف پایداری بیشتری دارند.
                        </li>
                    </ul>
                    <p>
                        البته معایبی هم وجود دارد که تا حدی قابل پیش‌بینی هستند.</p>

                    <p><strong>معایب زنجیره تفکر</strong></p>
                    <p>پاسخ مدل شامل گام‌های استدلالی زنجیره تفکر است، که یعنی توکن‌های خروجی بیشتری تولید می‌شود. این
                        باعث می‌شود هزینه پیش‌بینی‌ها بیشتر بشه و زمان بیشتری طول بکشه.</p>
                    <p>
                        برای توضیح مثال در جدول 11، ابتدا بیایم یه درخواست بدون استفاده از CoT بنویسیم تا نقاط ضعف یک
                        مدل زبانی بزرگ رو نشون بدیم.
                    </p>

                    <p><strong>مثال زنجیره تفکر:</strong></p>


                    <img src="images/CoT4.png" width="700" />

                    <p>
                        خوب، این جواب کاملاً اشتباهه!
                        واقعیت اینه که مدل‌های زبانی بزرگ (LLMs) اغلب توی کارهای ریاضی به مشکل می‌خورن و ممکنه حتی برای
                        یه کار ساده مثل ضرب دو تا عدد، جواب اشتباه بدن. دلیلش اینه که این مدل‌ها روی حجم زیادی از متن
                        آموزش دیدن و ریاضیات ممکنه نیاز به یه روش متفاوت داشته باشه. حالا بیایم ببینیم اگه از گام‌های
                        استدلالی میانی استفاده کنیم، آیا خروجی بهتر می‌شه یا نه.
                    </p>
                    <img src="images/CoT5.png" width="700" />

                    <p>
                        خوبه، حالا جواب نهایی درسته!
                        این اتفاق افتاد چون ما به مدل دستور واضح دادیم که هر گام رو توضیح بده، به جای اینکه فقط یه جواب
                        بده. جالبه که مدل 17 سال افزایش رو جمع کرد. اگه من بودم، توی ذهنم فاصله سال‌ها بین خودم و
                        پارتنرم رو حساب می‌کردم و بعد جمعشون می‌کردم، مثلاً (20+(9-3)). بیایم به مدل کمک کنیم یه کم شبیه
                        من فکر کنه!
                    </p>
                    <p>
                        جدول 12 یه نمونه از زنجیره تفکر بدون نمونه (Zero-Shot CoT) هست. زنجیره تفکر وقتی با تک‌نمونه
                        (Single-Shot) یا چندنمونه (Few-Shot) ترکیب بشه، خیلی قدرتمند می‌شه، همون‌طور که توی جدول 13
                        می‌تونید ببینید.
                    </p>
                    <img src="images/CoT6.png" width="700" />

                    <p>
                        زنجیره تفکر برای کارهای مختلفی مفیده. چند مثال:
                    </p>
                    <ul>
                        <li>
                            تولید کد (Code Generation): می‌تونید درخواست رو به چند گام تقسیم کنید و هر گام رو به خطوط
                            خاصی از کد مرتبط کنید.
                        </li>
                        <li>

                            ایجاد داده مصنوعی (Synthetic Data): مثلاً وقتی یه نقطه شروع دارید، مثل «محصول اسمش XYZ هست،
                            یه توضیح بنویس و مدل رو از فرضیاتی که بر اساس اسم محصول می‌کنی، هدایت کن.»
                        </li>
                        <li>

                            به طور کلی، هر کاری که بشه با صحبت کردن و توضیح دادن حلش کرد، کاندیدای خوبی برای زنجیره
                            تفکره. اگه بتونید گام‌های حل مسئله رو توضیح بدید، زنجیره تفکر رو امتحان کنید!
                        </li>

                    </ul>

                </div>

                <div id="خودسازگاری-self-consistency" class="section">
                    <h3>خودسازگاری (Self-consistency)</h3>
                    <p>خودسازگاری یک تکنیک است که در آن از مدل خواسته می‌شود چندین مسیر استدلال را برای یک مسئله در نظر
                        بگیرد و سپس پاسخی را انتخاب کند که بیشترین سازگاری را دارد.</p>

                    <p>
                        گرچه مدل‌های زبانی بزرگ (LLMs) در وظایف مختلف پردازش زبان طبیعی (NLP) موفقیت‌های چشمگیری
                        داشته‌اند، اما توانایی آن‌ها در استدلال اغلب به‌عنوان یک محدودیت شناخته می‌شود که فقط با بزرگ‌تر
                        کردن اندازه مدل حل نمی‌شود. همون‌طور که در بخش قبلی درباره زنجیره تفکر (Chain of Thought - CoT)
                        یاد گرفتیم، می‌شه به مدل دستور داد که مثل یه انسان، گام‌های استدلالی رو برای حل مسئله تولید کنه.
                        اما CoT از یه روش ساده به اسم رمزگشایی حریصانه (Greedy Decoding) استفاده می‌کنه که اثرگذاری‌ش رو
                        محدود می‌کنه.
                    </p>
                    <p>
                        خود-سازگاری (Self-Consistency) یه روش پیشرفته‌ست که نمونه‌برداری (Sampling) و رأی‌گیری اکثریت
                        (Majority Voting) رو ترکیب می‌کنه تا مسیرهای استدلالی متنوعی تولید کنه و پاسخی که بیشترین
                        سازگاری رو داره انتخاب کنه. این روش دقت و انسجام پاسخ‌های تولیدشده توسط مدل‌های زبانی رو بهبود
                        می‌ده. خود-سازگاری یه جور احتمال شبه‌تصادفی (Pseudo-Probability) برای درست بودن یه پاسخ ارائه
                        می‌ده، ولی خب، هزینه‌های بالایی هم داره.
                    </p>

                    مراحل خود-سازگاری
                    <ul>
                        <li>
                            تولید مسیرهای استدلالی متنوع:
                            همون درخواست (Prompt) چندین بار به مدل داده می‌شه. تنظیم دمای بالا (High Temperature) باعث
                            می‌شه مدل مسیرهای استدلالی و دیدگاه‌های متفاوتی برای
                            مسئله تولید کنه.
                        </li>
                        <li>

                            استخراج پاسخ از هر خروجی:
                            از هر پاسخ تولیدشده، جواب نهایی جدا می‌شه.
                        </li>
                        <li>

                            انتخاب شایع‌ترین پاسخ:
                            پاسخی که بیشترین تکرار رو داره، به‌عنوان جواب نهایی انتخاب می‌ش
                        </li>
                    </ul>

                    <p>مثال: سیستم طبقه‌بندی ایمیل
                        <br />
                        بیایم یه مثال از یه سیستم طبقه‌بندی ایمیل ببینیم که ایمیل‌ها رو به دو دسته مهم (IMPORTANT) یا
                        غیرمهم (NOT IMPORTANT) تقسیم می‌کنه. یه درخواست زنجیره تفکر بدون نمونه (Zero-Shot CoT) چندین بار
                        به مدل فرستاده می‌شه تا ببینیم آیا پاسخ‌ها بعد از هر بار ارسال فرق می‌کنن یا نه. توجه کنید به
                        لحن دوستانه، انتخاب کلمات و کنایه (Sarcasm) که توی ایمیل استفاده شده. همه این‌ها ممکنه مدل زبانی
                        رو گمراه کنن!
                    </p>

                    <p><strong>مثال خودسازگاری:</strong></p>

                    <img src="images/self01.png" width="700" />
                    <img src="images/self02.png" width="700" />
                    <img src="images/self03.png" width="700" />

                </div>

                <div id="درخت-تفکرات-tree-of-thoughts" class="section">
                    <h3>درخت تفکرات (Tree of Thoughts)</h3>
                    <p>درخت تفکرات (ToT) یک گسترش از زنجیره تفکر است که به مدل اجازه می‌دهد چندین مسیر استدلال را کاوش
                        کند و مسیرهای غیرامیدوارکننده را هرس کند.</p>

                    <p><strong>مثال درخت تفکرات:</strong></p>
                    <img src="images/ToT.png" width="700" />

                    <pre><code>Solve this puzzle by exploring multiple possible solutions:

You have 8 balls that all look identical. One of them is slightly heavier than the others. Using a balance scale, how can you identify the heavier ball with just 2 weighings?

Let's explore different approaches:
Approach 1:
Approach 2:
Approach 3:

Now, let's evaluate each approach and determine which one is correct.</code></pre>
                </div>

                <div id="واکنش-react" class="section">
                    <h3>ReAct (Reason & Act)</h3>

                    <p>
                        پرامپت ReAct یک پارادایم جدید در مدل‌های زبانی بزرگ (LLMs) هست که به آن‌ها کمک می‌کند وظایف
                        پیچیده را با استفاده از استدلال به زبان طبیعی (natural language) و ترکیب آن با ابزارهای خارجی
                        (مثل جستجو، code interpreter و غیره) حل کنند. این روش به مدل اجازه می‌دهد کارهایی مثل تعامل با
                        APIها برای دریافت اطلاعات انجام دهد، که گامی اولیه به سمت مدل‌سازی ایجنت (Agent Modeling) محسوب
                        می‌شود.

                    </p>
                    <p>
                        در ReAct از نحوه عملکرد انسان‌ها در دنیای واقعی تقلید می‌شود؛ ما هم به‌صورت کلامی استدلال
                        می‌کنیم و برای به‌دست آوردن اطلاعات، اقداماتی انجام می‌دهیم. ReAct در مقایسه با دیگر روش‌های
                        Prompt Engineering در حوزه‌های مختلف عملکرد خوبی دارد.
                    </p>
                    <p>
                        نحوه کار ReAct، با ترکیب استدلال و عمل در یک حلقه فکر-عمل (thought-action) کار می‌کند:
                    </p>
                    <p>
                        ابتدا مدل درباره مسئله استدلال می‌کند و یک طرح عملی تولید می‌کند. سپس اقدامات موجود در طرح را
                        اجرا می‌کند و نتایج را مشاهده می‌کند. مدل از این مشاهدات برای به‌روزرسانی استدلالش استفاده
                        می‌کند و یک طرح عملی جدید می‌سازد. این فرآیند ادامه پیدا می‌کند تا مدل به راه‌حل مسئله برسد.
                    </p>
                    <p>
                        آزمایش ReAct در عمل
                    </p>
                    <p>

                        برای دیدن این روش در عمل، باید کدی بنویسید. در قطعه کد شماره 1، در اینجا از فریم‌ورک LangChain
                        در زبان پایتون به همراه VertexAI (از بسته google-cloud-aiplatform) و بسته google-search-results
                        استفاده شده.

                    </p>
                    <p>
                        برای اجرای این نمونه، باید یک کلید SerpAPI رایگان از آدرس <a
                            href="https://serpapi.com/manage-api-key"
                            target="_blank">https://serpapi.com/manage-api-key</a> بسازید و متغیر محیطی SERPAPI_API_KEY
                        را تنظیم کنید
                    </p>
                    <p><strong>مثال واکنش:</strong></p>
                    <img src="images/ReAct.png" width="700" />

                    <p>
                        حالا بیایم یه کد پایتون بنویسیم که وظیفه‌ای برای مدل زبانی بزرگ (LLM) تعریف کنه:
                        اعضای گروه متالیکا چندتا بچه دارند؟
                    </p>
                    <img src="images/ReAct1.png" width="700" />
                    <p>

                        توضیح قطعه کد شماره 2
                        <br />
                        قطعه کد شماره 2 نتیجه رو نشون می‌ده. توجه کنید که ReAct یه زنجیره از پنج جستجو انجام می‌ده.
                        درواقع، مدل زبانی نتایج جستجوی گوگل رو بررسی می‌کنه تا اسامی اعضای گروه رو پیدا کنه. بعد، نتایج
                        رو به‌عنوان مشاهدات فهرست می‌کنه و استدلالش رو برای جستجوی بعدی ادامه می‌ده.
                        <br />
                        در این کد، مدل متوجه می‌شه که گروه متالیکا چهار عضو داره. بعد، برای هر عضو گروه جستجو می‌کنه تا
                        تعداد بچه‌هاشون رو پیدا کنه و همه رو جمع می‌زنه. در نهایت، تعداد کل بچه‌ها رو به‌عنوان پاسخ
                        نهایی برمی‌گردونه.
                    </p>
                </div>
            </div>

            <div id="پرامپت-برای-کدنویسی" class="section">
                <h2>5. پرامپت برای کدنویسی</h2>
                <p>مدل‌های زبانی بزرگ (LLM) می‌توانند در نوشتن، توضیح، ترجمه و اشکال‌زدایی کد کمک کنند. در این بخش،
                    تکنیک‌های پرامپت مختلف برای کار با کد را بررسی می‌کنیم.</p>

                <div id="نوشتن-کد" class="section">
                    <h3>نوشتن کد</h3>
                    <p>هنگام درخواست از LLM برای نوشتن کد، ارائه دستورالعمل‌های واضح و مشخص کردن زبان برنامه‌نویسی مورد
                        نظر مهم است.</p>

                    <p><strong>مثال پرامپت برای نوشتن کد:</strong></p>

                    <img src="images/wiring-code.png" width="700" />

                    <p>برای وظایف پیچیده‌تر، می‌توانید جزئیات بیشتری ارائه دهید:</p>

                    <pre><code>Create a Python class for a Bank Account with the following features:
1. Initialize with account holder name and starting balance
2. Methods for deposit and withdrawal
3. A method to calculate interest (assume 2% annual interest)
4. Error handling for insufficient funds
5. A method to display the current balance and account details

Use proper documentation and follow PEP 8 style guidelines.</code></pre>
                </div>

                <div id="توضیح-کد" class="section">
                    <h3>توضیح کد</h3>
                    <p>LLM‌ها می‌توانند در توضیح کد موجود کمک کنند، که برای یادگیری یا مستندسازی مفید است.</p>

                    <p><strong>مثال پرامپت برای توضیح کد:</strong></p>

                    <img src="images/explain01.png" width="700" />
                    <img src="images/explain02.png" width="700" />

                </div>

                <div id="ترجمه-کد" class="section">
                    <h3>ترجمه کد</h3>
                    <p>LLM‌ها می‌توانند کد را از یک زبان برنامه‌نویسی به زبان دیگر ترجمه کنند.</p>

                    <p><strong>مثال پرامپت برای ترجمه کد:</strong></p>

                    <img src="images/translate1.png" width="700" />
                    <img src="images/translate2.png" width="700" />

                </div>

                <div id="اشکالزدایی-و-بررسی-کد" class="section">
                    <h3>اشکال‌زدایی و بررسی کد</h3>
                    <p>LLM‌ها می‌توانند در شناسایی و رفع اشکالات در کد کمک کنند.</p>

                    <p><strong>مثال پرامپت برای اشکال‌زدایی کد:</strong></p>

                    <img src="images/debug-review.png" width="700" />

                    <img src="images/debug-prompt1.png" width="700" />
                    <img src="images/debug-prompt2.png" width="700" />
                    <img src="images/debug-prompt3.png" width="700" />
                    <img src="images/debug-prompt4.png" width="700" />
                </div>
            </div>

            <div id="بهترین-شیوههای-مهندسی-پرامپت" class="section">
                <h2>6. بهترین شیوه‌های مهندسی پرامپت
                    Best Practices
                </h2>
                <p>در این بخش، بهترین شیوه‌ها و نکات کاربردی برای مهندسی پرامپت موثر را بررسی می‌کنیم.</p>

                <div id="ارائه-مثالها" class="section">
                    <h3>ارائه مثال‌ها</h3>
                    <p>مهم‌ترین روش ارايه مثال هست (تک-شات و چند-شات) با پرامپت هست</p>
                    <p>ارائه مثال‌های واضح می‌تواند به مدل کمک کند تا الگوها را بهتر درک کند و پاسخ‌های دقیق‌تری تولید
                        کند. مثال بسیار بهیته هست چون شبیه یک ابزار آموزشی برای مدل عمل میکند.</p>

                    <p><strong>نکته:</strong> برای وظایف پیچیده، از پرامپت چند-شات با مثال‌های متنوع استفاده کنید.</p>

                    <pre><code>Translate the following English phrases to French:

English: Hello, how are you?
French: Bonjour, comment allez-vous?

English: I would like to order a coffee, please.
French: Je voudrais commander un café, s'il vous plaît.

English: Where is the nearest train station?
French:</code></pre>

                    <div id="طراحی-با-سادگی" class="section">
                        <h3>طراحی با سادگی</h3>
                        <p>پرامپت‌های ساده و مستقیم اغلب بهترین نتایج را تولید می‌کنند. از زبان پیچیده یا دستورالعمل‌های
                            مبهم خودداری کنید.</p>
                        <p>اگر پرامپت برای خود شما هم گنگ هست، مطمعن باشید برای مدل هم نامفهوم است.</p>

                        <img src="images/bp-simplicity.png" width="700" />

                        <p>
                            در نوشتن پرامپ از افعال شبیه زیر می‌توانید استفاده کنید:
                        </p>
                        <p dir="ltr">
                            <b>
                                Act, Analyze, Categorize, Classify, Contrast, Compare, Create, Describe, Define,
                                Evaluate, Extract, Find, Generate, Identify, List, Measure, Organize, Parse, Pick,
                                Predict, Provide, Rank, Recommend, Return, Retrieve, Rewrite, Select, Show, Sort,
                                Summarize, Translate, Write.
                            </b>
                        </p>
                    </div>

                    <div id="مشخص-کردن-خروجی" class="section">
                        <h3>مشخص کردن خروجی</h3>
                        <p>
                            خروجی مورد نظرتان را به وضوح مشخص کنید. یک دستور مختصر ممکن است نتواند LLM را به اندازه کافی
                            راهنمایی کند و ممکن است خیلی کلی باشد.
                        </p>
                        <img src="images/bp-output.png" width="700" />

                        <!-- <pre><code>Create a 5-day weather forecast for Tokyo. Format the output as a table with columns for Day, Temperature (°C), and Conditions.</code></pre> -->
                        <!-- Content placeholder -->
                    </div>

                    <div id="استفاده-از-دستورالعملها-به-جای-محدودیتها" class="section">
                        <h3>
                            استفاده از دستورالعمل‌ها به جای محدودیت‌ها</h3>
                        <p>به جای گفتن اینکه مدل چه کاری نکند، به آن بگویید چه کاری انجام دهد.</p>
                        <p>در پرامپت (Prompting) برای هدایت خروجی یک مدل زبانی بزرگ (LLM)، از دستورات و محدودیت‌ها
                            استفاده می‌کنیم. این دو ابزار به ما کمک می‌کنند تا پاسخ مدل را به شکلی که می‌خواهیم شکل
                            دهیم. در ادامه، این مفاهیم را به زبان ساده و قابل فهم توضیح می‌دهم:</p>

                        <p><b>دستورات (Instruction) چیست؟</b></p>
                        <p>دستورات، راهنمایی‌های مشخص و واضحی هستند که به مدل می‌گویند پاسخش چه شکل، سبک یا محتوایی باید
                            داشته باشد. به عبارت دیگر، دستورات به مدل می‌گویند که چه کاری انجام دهد یا چه چیزی تولید
                            کند.</p>
                        <p>مثال: «پاسخ را به صورت یک پاراگراف کوتاه بنویس.»<br>این نوع راهنمایی به مدل کمک می‌کند تا
                            دقیقاً بفهمد چه انتظاری از آن داریم و کارش را در مسیر درست پیش ببرد.</p>

                        <p><b>محدودیت‌ها (Constraint) چیست؟</b></p>
                        <p>محدودیت‌ها، قوانینی هستند که مشخص می‌کنند مدل چه کاری نباید انجام دهد یا از چه چیزی باید دوری
                            کند. این‌ها مثل خطوط قرمزی هستند که پاسخ مدل باید درون آن‌ها بماند.</p>
                        <p>مثال: «از کلمات پیچیده و فنی استفاده نکن.»<br>محدودیت‌ها کمک می‌کنند تا خروجی مدل در چارچوب
                            مشخص و قابل قبولی بماند.</p>

                        <p><b>چرا دستورات بهتر از محدودیت‌ها هستند؟</b></p>
                        <p>تحقیقات جدید نشان می‌دهد که استفاده از دستورات مثبت معمولاً بهتر از تکیه زیاد بر محدودیت‌ها
                            جواب می‌دهد. این موضوع شبیه به رفتار خود ما آدم‌هاست؛ ما هم راهنمایی‌های مثبت را بیشتر از
                            لیست بلندبالای «این کار را نکن» دوست داریم.</p>

                        <p><b>دلیل بهتر بودن دستورات:</b></p>
                        <ul>
                            <li>دستورات به‌طور مستقیم به مدل می‌گویند که چه نتیجه‌ای می‌خواهیم</li>
                            <li>امکان خلاقیت بیشتر در چارچوب مشخص</li>
                            <li>جلوگیری از سردرگمی مدل</li>
                        </ul>

                        <p><b>مشکلات محدودیت‌ها:</b></p>
                        <ul>
                            <li>امکان ایجاد سردرگمی در مدل</li>
                            <li>کاهش خلاقیت</li>
                            <li>احتمال ایجاد تناقض بین محدودیت‌ها</li>
                        </ul>

                        <p><b>کی از محدودیت‌ها استفاده کنیم؟</b></p>
                        <p>با اینکه دستورات مثبت بهتر هستند، محدودیت‌ها هم در جاهایی به کار می‌آیند:</p>
                        <ul>
                            <li>جلوگیری از تولید محتوای مضر یا اشتباه</li>
                            <li>نیاز به قالب/سبک خاص (مثلاً محدودیت تعداد کلمات)</li>
                        </ul>

                        <p> <b>نکته مهم: چطور بهتر درخواست بنویسیم؟</b></p>
                        <p>هر وقت می‌شود، از دستورات مثبت استفاده کنید. به جای اینکه به مدل بگویید چه کاری نکند، بگویید
                            چه کاری بکند. این کار سردرگمی را کم می‌کند و باعث می‌شود پاسخ دقیق‌تر و بهتر باشد.</p>
                        <p>مثال: به جای «مبهم نباش»، بگویید «جزئیات واضح و مشخص بده.»<br>این تغییر ساده باعث می‌شود مدل
                            بهتر بفهمد و نتیجه بهتری بدهد.</p>

                        <p> <b>بهترین روش چیست؟</b></p>
                        <ol>
                            <li>اول با دستورات شروع کنید</li>
                            <li>فقط در صورت نیاز از محدودیت‌ها استفاده کنید</li>
                            <li>ترکیب‌های مختلف را آزمایش کنید</li>
                            <li>نتایج را مستندسازی کنید</li>
                        </ol>

                        <img src="images/bp-intructions.png" width="700" />

                    </div>

                    <div id="کنترل-طول-توکن" class="section">
                        <h3>کنترل طول توکن</h3>
                        <p>برای کنترل طول پاسخ، محدودیت‌های خاصی را مشخص کنید.</p>
                        <p>مثال:</p>

                        <img src="images/bp-maxtoken.png" width="500" />
                        <!-- <pre><code>Summarize the history of artificial intelligence in exactly 3 paragraphs.</code></pre> -->
                    </div>

                    <div id="استفاده-از-متغیرها-در-پرامپتها" class="section">
                        <h3>استفاده از متغیرها در پرامپت‌ها</h3>
                        <p>
                            برای استفاده دوباره از پرامپت‌ها و پویاتر کردن آن‌ها، از متغیرها در پرامپت استفاده کنید که می‌توانند برای ورودی‌های مختلف تغییر کنند. برای مثال، همان‌طور که در جدول ۲۰ نشان داده شده، پرامپتی که اطلاعاتی درباره یک شهر می‌دهد. به جای نوشتن ثابت نام شهر در پرامپت، از یک متغیر استفاده کنید. متغیرها می‌توانند با جلوگیری از تکرار، 
                        </p>
                        <p>
                            در زمان و تلاش شما صرفه‌جویی کنند. اگر نیاز دارید همان اطلاعات را در چند پرامپت استفاده کنید، می‌توانید آن‌ها را در یک متغیر ذخیره کرده و سپس در هر پرامپت به آن متغیر اشاره کنید. این کار وقتی پرامپت‌ها را در برنامه‌های خودتان ادغام می‌کنید، بسیار منطقی است.
                        </p>

                        <img src="images/bp-variables.png" width="700" />

                        <!-- <pre><code>Analyze the sentiment of the following text as positive, negative, or neutral:
{{TEXT}}</code></pre> -->
                        <!-- Content placeholder -->
                    </div>

                    <div id="آزمایش-با-فرمتهای-ورودی-و-سبکهای-نوشتاری" class="section">
                        <h3>آزمایش با فرمت‌های ورودی و سبک‌های نوشتاری</h3>
                        <p>فرمت‌های مختلف پرامپت را آزمایش کنید تا ببینید کدام یک بهترین نتایج را تولید می‌کند.</p>

                        <p>

                            مدل‌های هوش مصنوعی مختلف، تنظیماتشان، نوع درخواست (پرامپت)، کلماتی که انتخاب می‌کنید، و سبک نوشتنتان، همگی روی جوابی که می‌گیرید تأثیر می‌گذارند و می‌توانند نتایج متفاوتی ایجاد کنند.
                        </p>
                        <p>
                            بنابراین، مهم است که با ویژگی‌های مختلف درخواستتان آزمایش کنید؛ مانند:
                            سبک نوشتن (رسمی، دوستانه، ساده و...)
                            انتخاب کلمات (استفاده از مترادف‌ها یا عبارات مختلف)
                            نوع درخواست (مثلاً اینکه درخواستتان سوالی باشد، یک جمله خبری باشد، یا یک دستورالعمل)
                        </p>
                        <p>
                            مثال:
                            فرض کنید می‌خواهید مدل متنی درباره کنسول بازی انقلابی "سگا دریم‌کست" بنویسد. می‌توانید درخواستتان را به شکل‌های مختلفی بنویسید، و هر کدام جواب متفاوتی خواهد داد:                            
                        </p>
                        <p>
                            <div style="text-align: center; width: 100%;" dir="ltr">Question: What was the Sega Dreamcast and why was it such a revolutionary console?

                            </div>
                            <div style="text-align: center; width: 100%;">
                                سوال: سگا دریم‌کست چه بود و چرا یک کنسول انقلابی محسوب می‌شد؟
                            </div>
                        </p>
                        <p>
                            <div style="text-align: center; width: 100%;" dir="ltr">Statement: The Sega Dreamcast was a sixth-generation video game console released by
                                Sega in 1999. It...

                            </div>
                            <div style="text-align: center; width: 100%;">
                                جمله خبری: سگا دریم‌کست یک کنسول بازی نسل ششم بود که توسط سگا در سال ۱۹۹۹ منتشر شد. این کنسول...
                            </div>
                        </p>

                        <p>
                            <div style="text-align: center; width: 100%;" dir="ltr">Instruction: Write a single paragraph that describes the Sega Dreamcast console and explains why it was so revolutionary.

                            </div>
                            <div style="text-align: center; width: 100%;">
                                دستورالعمل: یک پاراگراف بنویس که کنسول سگا دریم‌کست را توصیف کند و توضیح دهد چرا اینقدر انقلابی بود.
                            </div>
                        </p>

                    </div>


                    <div id="" class="section">
                        <h3>
                            نکته مهم برای وظایف دسته‌بندی
                        </h3>
                        <p>
وقتی از چند مثال آموزشی استفاده می‌کنید، کلاس‌ها (دسته‌ها) را با هم ترکیب کنید. معمولاً ترتیب مثال‌های آموزشی (few-shot examples) که به مدل می‌دهید، نباید تأثیر زیادی داشته باشد.
</p><p>
اما، وقتی کار شما دسته‌بندی است (مثلاً تشخیص ایمیل اسپم از غیر اسپم، یا دسته‌بندی نظرات مشتریان به مثبت و منفی)، خیلی مهم است که کلاس‌های مختلف پاسخ را در مثال‌هایتان مخلوط کنید. 
</p>
<p>
یعنی اگر مثال‌هایی برای کلاس "مثبت" و کلاس "منفی" دارید، آن‌ها را یکی در میان یا با ترتیب‌های مختلف بیاورید، نه اینکه همه‌ی مثال‌های "مثبت" را پشت سر هم و بعد همه‌ی مثال‌های "منفی" را بیاورید.
</p>
<p>
چرا این کار مهم است؟ چون اگر این کار را نکنید، ممکن است مدل به جای یاد گرفتن ویژگی‌های اصلی هر کلاس، فقط ترتیب آمدن مثال‌ها را یاد بگیرد. با ترکیب کردن کلاس‌ها، مطمئن می‌شوید که مدل یاد می‌گیرد چه چیزی واقعاً یک متن را "مثبت" یا "منفی" می‌کند، نه اینکه صرفاً ترتیب مثال‌ها را حفظ کند.
این کار باعث می‌شود مدل در مواجهه با داده‌های جدید که قبلاً ندیده، عملکرد بهتر و قابل اعتمادتری داشته باشد.
</p>
<b>یک راهنمایی:</b>
<br/>
معمولاً خوب است که با حدود ۶ مثال آموزشی شروع کنید و از همان‌جا دقت مدل را بسنجید و ببینید آیا نیاز به تغییر یا مثال‌های بیشتر دارید یا نه.
                    </div>


                    <div id="" class="section">
                        <h3>
                            کار با فرمت‌های خروجی
                        </h3>
                        <p>
                            علاوه‌بر اینکه به فرمت ورودی پرامپت توجه می‌کنید، بهتره با فرمت خروجی هم آزمایش کنید. برای کارهای غیرخلاقانه مثل استخراج، انتخاب، تجزیه، مرتب‌سازی، رتبه‌بندی یا دسته‌بندی داده‌ها، بهتره خروجی رو به صورت ساختاریافته مثل JSON یا XML دریافت کنید.
                        </p>
                        <p>
                            برگردوندن خروجی به شکل JSON برای کارهایی که نیاز به استخراج داده دارن چند تا مزیت داره. مثلاً در دنیای واقعی، من لازم نیست خودم این فرمت JSON رو دستی بسازم؛ می‌تونم داده‌ها رو به صورت مرتب‌شده دریافت کنم (که مخصوصاً برای کار با تاریخ و زمان خیلی مفیده). اما مهم‌تر از همه اینه که وقتی از مدل می‌خوایم خروجی رو به صورت JSON بده، باعث می‌شه مدل ساختاری فکر کنه و کمتر دچار "توهم" یا اشتباهات بی‌اساس بشه.
                        </p>
                        <p>
                            خلاصه‌ی مزایای استفاده از JSON برای خروجی:
                        </p>                        
                        <ul>
                            <li>
                                همیشه خروجی رو با یک سبک و فرمت ثابت می‌گیرید
                                
                            </li>
                            <li>
                                تمرکز فقط روی داده‌هایی هست که شما می‌خواید
                                
                            </li>
                            <li>
                                احتمال اشتباه و خیال‌پردازی مدل کمتر می‌شه
                                
                            </li>
                            <li>
                                می‌تونید روابط بین داده‌ها رو مشخص کنید
                                
                            </li>
                            <li>
                                نوع داده‌ها (مثل عدد، متن، تاریخ) رو دارید
                                
                            </li>
                            <li>
                                می‌تونید راحت داده‌ها رو مرتب کنید

                            </li>
                        </ul>
                        
                        
                        
                        
                        
                        
                        در جدول ۴ از بخش "few-shot prompting" یک نمونه از خروجی ساختاریافته آورده شده.

                    </div>

                    <div id="" class="section">
                        <h3>
                            JSON Repair
                        </h3>
                        <p>
                            درسته که برگردوندن داده به فرمت JSON مزایای زیادی داره، اما این روش خالی از اشکال هم نیست. ساختارمند بودن JSON، در حالی که برای پردازش و استفاده در برنامه‌ها خیلی مفیده، ولی به نسبت متن ساده تعداد توکن‌های بیشتری مصرف می‌کنه. این یعنی هم زمان پردازش بیشتر می‌شه و هم هزینه‌ها بالاتر می‌ره.
                        </p>
                        <p>
                            از طرف دیگه، چون JSON پرحجم‌تره، ممکنه به‌راحتی کل پنجره‌ی خروجی مدل رو پر کنه. این موضوع وقتی دردسرساز می‌شه که خروجی مدل به دلیل محدودیت تعداد توکن‌ها ناگهان قطع بشه. در این حالت، خروجی JSON ناقص می‌مونه (مثلاً یه آکولاد یا براکت بسته فراموش می‌شه) و در نتیجه دیگه قابل استفاده نیست.
                        </p>
                        <p>
                            خوشبختانه، ابزارهایی مثل کتابخونه‌ی json-repair که در PyPI موجوده، توی این شرایط خیلی به کار میان. این کتابخونه به شکل هوشمند تلاش می‌کنه JSONهای ناقص یا خراب‌شده رو به‌صورت خودکار اصلاح کنه. به همین خاطر، وقتی با خروجی JSON مدل‌های زبانی کار می‌کنید، مخصوصاً وقتی ممکنه خروجی ناقص باشه، این ابزار می‌تونه یه کمک حیاتی باشه.
                        </p>

                    </div>

                    <div id="" class="section">
                        <h3>کار با Schemaها</h3>

                        <p>
                            استفاده از خروجی ساختاریافته با فرمت JSON یه راه‌حل خیلی خوبه، همون‌طور که بارها در این مقاله دیدیم. اما ورودی چی؟ درسته که JSON برای ساختار دادن به خروجی عالیه، ولی می‌تونه برای ساختار دادن به ورودی هم خیلی مفید باشه. اینجاست که JSON Schema وارد می‌شه.
                        </p>
                        <p>

JSON Schema یه قالب مشخص برای ورودی JSON تعریف می‌کنه؛ یعنی دقیقا تعیین می‌کنه چه ساختاری باید داشته باشه و چه نوع داده‌هایی داخلش قرار بگیره. وقتی چنین اسکیمایی رو به مدل می‌دید، در واقع یه نقشه‌ی شفاف بهش می‌دید تا بدونه قراره چه اطلاعاتی رو دریافت کنه. این کار کمک می‌کنه مدل تمرکزش رو روی اطلاعات مهم بذاره و احتمال اشتباه در تفسیر ورودی کمتر بشه.
</p><p>
علاوه‌بر این، اسکیمای JSON می‌تونه روابط بین بخش‌های مختلف داده رو مشخص کنه و حتی مدل رو از نظر زمانی هم "آگاه" کنه، مثلاً با تعیین فیلدهایی برای تاریخ یا زمان با فرمت خاص.
</p><p>
یه مثال ساده:
<br/>
فرض کنیم می‌خواید از یه مدل زبانی برای نوشتن توضیحات محصولات در یک فروشگاه اینترنتی استفاده کنید. به جای اینکه فقط یه متن آزاد و بی‌ساختار درباره‌ی محصول بدید، می‌تونید با استفاده از JSON Schema ویژگی‌های محصول رو به صورت دقیق و ساختاریافته مشخص کنید.
</p>
<img src="images/schema01.png" width="700" />
<p>
    بعد از اینکه اسکیمای JSON رو مشخص کردید، حالا می‌تونید داده‌های واقعی محصول رو به‌صورت یه شیء JSON ارائه بدید که با اون اسکیمای تعریف‌شده هماهنگ باشه.
</p>
                        
<img src="images/schema01.png" width="700" />


<p>
    با پیش‌پردازش داده‌هاتون و به‌جای اینکه کل سندهای توضیح محصول رو به مدل بدید، اگر فقط اسکیمای JSON و داده‌ی واقعی رو بهش بدید، باعث می‌شید مدل درک خیلی واضح‌تری از ویژگی‌های محصول (مثل تاریخ عرضه و...) پیدا کنه. این کار باعث می‌شه مدل بتونه توضیحاتی تولید کنه که هم دقیق‌تر و هم مرتبط‌تر باشن.
</p>
<p>    
این روش ورودی ساختاریافته، که تمرکز مدل رو روی فیلدهای مهم و مرتبط می‌ذاره، مخصوصاً وقتی با حجم زیادی از داده‌ها کار می‌کنید یا وقتی می‌خواید مدل‌های زبانی رو توی اپلیکیشن‌های پیچیده‌تر استفاده کنید، خیلی مفیده و کارآمد.
</p>

                    </div>


                    <div id="بهترین-شیوههای-زنجیره-تفکر" class="section">
                        <h3>بهترین شیوه‌های زنجیره تفکر (CoT)</h3>
                        <p>برای مسائل پیچیده، از زنجیره تفکر استفاده کنید تا مدل را به استدلال قدم به قدم هدایت کنید.
                        </p>
                        <p>
                            باید پاسخ را بعد از توضیحات و استدلال‌ها بنویسید. چون وقتی استدلال‌ها را می‌نویسید، اطلاعاتی که مدل برای حدس زدن پاسخ نهایی استفاده می‌کند تغییر می‌کند.
                        </p>
                        <p>
                            وقتی از CoT و روش خود-سازگاری (Self-consistency) استفاده می‌کنید، باید بتوانید پاسخ نهایی را از متن درخواست جدا کنید، طوری که از استدلال‌ها مستقل باشد.
                        </p>
                        <p>
                            برای روش CoT، دما (Temperature) را روی ۰ بگذارید.
</p><p>
روش CoT بر اساس انتخاب ساده و مستقیم کار می‌کند، یعنی مدل زبانی کلمه بعدی را بر اساس بیشترین احتمال پیش‌بینی می‌کند. معمولاً وقتی از استدلال برای پیدا کردن پاسخ استفاده می‌کنید، فقط یک پاسخ درست وجود دارد. به همین دلیل، دما همیشه باید ۰ باشد.
</p>
                        </p>
                    </div>
                    <div id="مستندسازی-تلاشهای-مختلف-پرامپت" class="section">
                        <h3>مستندسازی تلاش‌های مختلف پرامپت</h3>
                        <p>پرامپت‌های خود و نتایج آن‌ها را مستند کنید تا بتوانید آنچه کار می‌کند و آنچه کار نمی‌کند را
                            پیگیری کنید.</p>

                        <p><strong>نمونه جدول مستندسازی:</strong></p>

                        <table>
                            <tr>
                                <th>نام پرامپت</th>
                                <th>هدف</th>
                                <th>مدل</th>
                                <th>دما</th>
                                <th>پرامپت</th>
                                <th>خروجی</th>
                                <th>نتیجه</th>
                            </tr>
                            <tr>
                                <td>طبقه‌بندی احساسات v1</td>
                                <td>طبقه‌بندی نظرات</td>
                                <td>gemini-pro</td>
                                <td>0.2</td>
                                <td>Classify...</td>
                                <td>POSITIVE</td>
                                <td>دقت 85%</td>
                            </tr>
                            <tr>
                                <td>طبقه‌بندی احساسات v2</td>
                                <td>طبقه‌بندی نظرات</td>
                                <td>gemini-pro</td>
                                <td>0.1</td>
                                <td>Determine...</td>
                                <td>POSITIVE</td>
                                <td>دقت 92%</td>
                            </tr>
                        </table>
                    </div>

                    <div id="جمعبندی-بهترین-شیوهها" class="section">
                        <h3>جمع‌بندی</h3>
                        <p>مهندسی پرامپت یک مهارت است که با تمرین و آزمایش بهبود می‌یابد. با استفاده از بهترین شیوه‌های
                            ذکر شده در این راهنما، می‌توانید پرامپت‌هایی ایجاد کنید که نتایج بهتری از مدل‌های زبانی بزرگ
                            تولید می‌کنند.</p>

                        <p>به یاد داشته باشید:</p>
                        <ul>
                            <li>واضح و مستقیم باشید</li>
                            <li>مثال‌های مناسب ارائه دهید</li>
                            <li>فرمت خروجی مورد نظر را مشخص کنید</li>
                            <li>از تکنیک‌های پیشرفته مانند زنجیره تفکر (CoT) برای مسائل پیچیده استفاده کنید</li>
                            <li>پرامپت‌های خود را مستند کنید و بهبود دهید</li>
                        </ul>

                        <p>با تمرین و آزمایش مداوم، مهارت‌های مهندسی پرامپت شما به طور قابل توجهی بهبود خواهد یافت.</p>
                    </div>
                </div>

                <div id="نمونه-کاربردهای-عملی" class="section">
                    <h2>7. نمونه کاربردهای عملی</h2>
                    <p>در این بخش، برخی از کاربردهای عملی مهندسی پرامپت را بررسی می‌کنیم که می‌توانید در پروژه‌های خود
                        از آن‌ها استفاده کنید.</p>

                    <div id="خلاصهسازی-متن" class="section">
                        <h3>خلاصه‌سازی متن</h3>
                        <pre><code>Summarize the following article in 3-5 sentences while preserving the key information:

{{ARTICLE_TEXT}}</code></pre>
                    </div>

                    <div id="تولید-محتوا" class="section">
                        <h3>تولید محتوا</h3>
                        <pre><code>Create a blog post about the benefits of meditation for mental health. The post should be approximately 500 words, include an introduction, 3 main benefits with supporting evidence, and a conclusion.</code></pre>
                    </div>

                    <div id="تحلیل-احساسات" class="section">
                        <h3>تحلیل احساسات</h3>
                        <pre><code>Analyze the sentiment of the following customer reviews and classify each as POSITIVE, NEGATIVE, or NEUTRAL:

1. "The product arrived on time and works perfectly. Very satisfied with my purchase."
2. "Decent quality but the price is too high compared to similar products."
3. "Absolutely terrible experience. The item was damaged and customer service was unhelpful."</code></pre>
                    </div>

                    <div id="استخراج-اطلاعات" class="section">
                        <h3>استخراج اطلاعات</h3>
                        <pre><code>Extract the following information from this resume:
- Name
- Email
- Phone number
- Education history (institution, degree, dates)
- Work experience (company, position, dates)
- Skills

Format the output as JSON.

{{RESUME_TEXT}}</code></pre>
                    </div>

                    <div id="تولید-کد" class="section">
                        <h3>تولید کد</h3>
                        <pre><code>Create a Python function that reads a CSV file containing student data (name, age, grade) and returns the average grade for each age group. Include error handling and comments.</code></pre>
                    </div>

                    <div id="ترجمه-زبان" class="section">
                        <h3>ترجمه زبان</h3>
                        <pre><code>Translate the following text from English to Spanish, maintaining the same tone and style:

{{TEXT_TO_TRANSLATE}}</code></pre>
                    </div>

                    <div id="پاسخ-به-سوالات" class="section">
                        <h3>پاسخ به سوالات</h3>
                        <pre><code>Answer the following questions about quantum computing:
1. What is a qubit?
2. How does quantum entanglement work?
3. What are the potential applications of quantum computing?
4. What are the current limitations of quantum computers?

Provide detailed but accessible explanations for someone with a basic understanding of physics.</code></pre>
                    </div>

                    <div id="ایجاد-طرح-کلی" class="section">
                        <h3>ایجاد طرح کلی</h3>
                        <pre><code>Create a detailed outline for a research paper on the impact of artificial intelligence on healthcare. Include main sections, subsections, and key points to address in each section.</code></pre>
                    </div>
                </div>

                <div id="جمعبندی" class="section">
                    <h2>8. جمع‌بندی</h2>
                    <p>مهندسی پرامپت یک مهارت ضروری برای استفاده موثر از مدل‌های زبانی بزرگ است. در این آموزش، ما مفاهیم
                        اساسی مهندسی پرامپت، تنظیمات خروجی LLM، تکنیک‌های مختلف پرامپت، کاربردهای کدنویسی و بهترین
                        شیوه‌ها را پوشش دادیم.</p>

                    <p>به یاد داشته باشید که مهندسی پرامپت یک فرآیند تکراری است. آزمایش با پرامپت‌های مختلف، تنظیمات مدل
                        و تکنیک‌ها برای دستیابی به بهترین نتایج ضروری است. با تمرین و تجربه، شما می‌توانید پرامپت‌هایی
                        ایجاد کنید که پاسخ‌های دقیق، مرتبط و مفید از LLM‌ها دریافت کنند.</p>

                    <p>نکات کلیدی برای به خاطر سپردن:</p>
                    <ol>
                        <li><strong>واضح و دقیق باشید</strong>: دستورالعمل‌های واضح و دقیق ارائه دهید.</li>
                        <li><strong>از مثال‌ها استفاده کنید</strong>: برای وظایف پیچیده، مثال‌هایی ارائه دهید تا مدل
                            الگو را درک کند.</li>
                        <li><strong>فرمت خروجی را مشخص کنید</strong>: ساختار و فرمت خروجی مورد نظر خود را مشخص کنید.
                        </li>
                        <li><strong>از تکنیک‌های پیشرفته استفاده کنید</strong>: برای مسائل پیچیده، از تکنیک‌هایی مانند
                            زنجیره تفکر (CoT) یا درخت تفکرات (ToT) استفاده کنید.</li>
                        <li><strong>تنظیمات مدل را بهینه کنید</strong>: با دما، Top-K و Top-P برای دستیابی به تعادل
                            مناسب بین خلاقیت و دقت آزمایش کنید.</li>
                        <li><strong>آزمایش و تکرار کنید</strong>: پرامپت‌های خود را مستند کنید، نتایج را ارزیابی کنید و
                            بر اساس بازخورد بهبود دهید.</li>
                    </ol>

                    <p>با پیشرفت فناوری LLM، مهندسی پرامپت نیز تکامل خواهد یافت. به روز ماندن با تکنیک‌های جدید و بهترین
                        شیوه‌ها به شما کمک می‌کند تا از این ابزارهای قدرتمند به طور موثر استفاده کنید.</p>
                </div>
                <p style="width: 100%; text-align: center;">
                    ☕                    این ترجمه با کمک Manus، Grok و ویرایش‌های خودم تهیه شده است.
                    <br/>
                    <span>آخرین بروزرسانی: ۲۶ فروردین ۱۴۰۴</span>
                    <br/>
                    <a dir="ltr" href="">@teal33t</a>
                </p>
        </div>
        </div>
</body>

</html>
